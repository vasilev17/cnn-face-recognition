{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f65a7f70-3072-4f18-a43d-6d6ad332624c",
   "metadata": {},
   "source": [
    "First we **import** the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e5522db-1ad6-4302-bd47-d052f39ebc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7116f0f9-5afe-4f40-b97b-7bd6a015098e",
   "metadata": {},
   "source": [
    "Then we can load the `VGG17 pre-trained model` and add our **custom layers** on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0092d5de-33f6-4ad3-98c3-fb114d10fc14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FloorMod in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomUniformV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FloorMod in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomUniformV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FloorMod in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomUniformV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FloorMod in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomUniformV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FloorMod in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomUniformV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FloorMod in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomUniformV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FloorMod in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomUniformV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FloorMod in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomUniformV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FloorMod in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomUniformV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FloorMod in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomUniformV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FloorMod in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomUniformV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FloorMod in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomUniformV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FloorMod in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomUniformV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FloorMod in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomUniformV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FloorMod in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op StatelessRandomUniformV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AddV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "# Load VGG16 pre-trained on ImageNet, excluding the top layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze all layers in VGG16 to retain pre-trained features\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers on top of the VGG16 base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)  # We can increase the number of units for increased model accuracy (makes training more hardware-intensive)\n",
    "x = Dense(2711, activation='softmax')(x)\n",
    "\n",
    "# Initialize the final model\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a34371-4d4d-47f0-8951-dfe82467c3d7",
   "metadata": {},
   "source": [
    "Now we need to **load** our dataset. In this case `Labeled Faces in the Wild (LFW)` with deep funneled images is implemented. In order to use the date we need to **segregate** the data into data for training and data for validation. When it comes to the dataset `deep funneled` images are chosen since the model is trained locally and there are hardware limitations which will be easier to adhere to using pre-optimized images. These limitations are also why only about half of the images available in `LFW` were used for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd7365cb-db4c-4d93-b170-a0a3044f92d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Aaron_Eckhart - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aaron_Guiel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aaron_Patterson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aaron_Peirsol - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aaron_Pena - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aaron_Sorkin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aaron_Tippin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Abbas_Kiarostami - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Abba_Eban - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Abdel_Aziz_Al-Hakim - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Abdel_Madi_Shabneh - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Abdel_Nasser_Assidi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Abdoulaye_Wade - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Abdulaziz_Kamilov - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Abdullah - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Abdullah_Ahmad_Badawi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Abdullah_al-Attiyah - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Abdullah_Gul - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Abdullah_Nasseef - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Abdullatif_Sener - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Abdul_Majeed_Shobokshi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Abdul_Rahman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Abel_Aguilar - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Abel_Pacheco - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Abid_Hamid_Mahmud_Al-Tikriti - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Abner_Martinez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Abraham_Foxman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aby_Har-Even - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adam_Ant - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adam_Freier - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adam_Herbert - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adam_Kennedy - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adam_Mair - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adam_Rich - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adam_Sandler - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adam_Scott - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adelina_Avila - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adel_Al-Jubeir - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adisai_Bodharamik - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adolfo_Aguilar_Zinser - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adolfo_Rodriguez_Saa - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adoor_Gopalakarishnan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adriana_Lima - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adriana_Perez_Navarro - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adrianna_Zuzic - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adrian_Annus - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adrian_Fernandez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adrian_McPherson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adrian_Murrell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adrian_Nastase - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Adrien_Brody - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Afton_Smith - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Agbani_Darego - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Agnelo_Queiroz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Agnes_Bruckner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ahmad_Jbarah - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ahmad_Masood - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ahmed_Ahmed - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ahmed_Chalabi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ahmed_Ghazi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ahmed_Ibrahim_Bilal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ahmed_Lopez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ahmed_Qureia - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ahmet_Demir - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ahmet_Necdet_Sezer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aicha_El_Ouafi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aidan_Quinn - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aileen_Riggin_Soule - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ainsworth_Dyer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ain_Seppik - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aishwarya_Rai - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aitor_Gonzalez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aiysha_Smith - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ai_Sugiyama - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ajit_Agarkar - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed AJ_Cook - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed AJ_Lamas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Akbar_Al_Baker - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Akbar_Hashemi_Rafsanjani - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Akhmed_Zakayev - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Akiko_Morigami - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Akmal_Taher - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alain_Cervantes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alain_Ducasse - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alanis_Morissette - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alanna_Ubach - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alan_Ball - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alan_Dershowitz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alan_Dreher - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alan_Greenspan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alan_Greer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alan_Jackson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alan_Mulally - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alan_Stonecipher - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alan_Tang_Kwong-wing - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alan_Trammell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alan_Zemaitis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alastair_Campbell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alastair_Johnston - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Albaro_Recoba - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alberta_Lee - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alberto_Acosta - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alberto_Fujimori - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alberto_Gonzales - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alberto_Ruiz_Gallardon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alberto_Sordi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Albert_Brooks - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Albert_Costa - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Albert_Montanes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Albert_Pujols - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Albrecht_Mentz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aldo_Paredes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alecos_Markides - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alec_Baldwin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alejandro_Atchugarry - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alejandro_Avila - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alejandro_Fernandez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alejandro_Gonzalez_Inarritu - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alejandro_Lembo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alejandro_Lerner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alejandro_Lopez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alejandro_Toledo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aleksander_Kwasniewski - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aleksander_Voloshin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alek_Wek - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alessandra_Cerna - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alessandro_Nesta - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alexander_Downer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alexander_Losyukov - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alexander_Lukashenko - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alexander_Payne - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alexander_Rumyantsev - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alexandra_Jackson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alexandra_Pelosi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alexandra_Rozovskaya - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alexandra_Spann - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alexandra_Stevenson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alexandra_Vodjanikova - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alexandre_Daigle - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alexandre_Despatie - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alexandre_Herchcovitch - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alexandre_Vinokourov - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alexa_Loren - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alexa_Vega - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alexis_Bledel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alexis_Dennisoff - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alex_Barros - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alex_Cabrera - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alex_Cejka - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alex_Corretja - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alex_Ferguson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alex_Gonzalez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alex_Holmes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alex_King - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alex_Penelas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alex_Popov - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alex_Sink - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alex_Wallau - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alex_Zanardi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alfonso_Cuaron - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alfonso_Portillo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alfonso_Soriano - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alfredo_di_Stefano - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alfredo_Moreno - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alfredo_Pena - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alfred_Ford - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alfred_Sant - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alice_Fisher - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alicia_Hollowell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alicia_Keys - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alicia_Molik - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alicia_Silverstone - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alicia_Witt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alimzhan_Tokhtakhounov - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alina_Kabaeva - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aline_Chretien - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alisha_Richman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alison_Krauss - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alison_Lohman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alistair_MacDonald - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ali_Abbas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ali_Abdullah_Saleh - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ali_Adbul_Karim_Madani - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ali_Ahmeti - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ali_Bin_Hussein - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ali_Fallahian - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ali_Hammoud - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ali_Khamenei - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ali_Mohammed_Maher - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ali_Naimi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Allan_Houston - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Allan_Kemakeza - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Allan_Wagner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Allen_Iverson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Allen_Rock - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Allison_Janney - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Allison_Searing - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Allyson_Felix - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ally_Sheedy - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alma_Powell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Almeida_Baptista - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alonzo_Mourning - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alvaro_Noboa - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alvaro_Silva_Calderon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alvaro_Uribe - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alyse_Beaupre - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Alyson_Hannigan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aly_Wagner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Al_Cardenas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Al_Davis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Al_Gore - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Al_Leiter - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Al_Pacino - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Al_Sharpton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Amanda_Beard - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Amanda_Bynes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Amanda_Coetzer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Amanda_Marsh - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Amanda_Plumer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Amber_Frey - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Amber_Tamblyn - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ambrose_Lee - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Amelia_Vega - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Amelie_Mauresmo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Amer_al-Saadi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Amporn_Falise - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Amram_Mitzna - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Amr_Moussa - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Amy_Brenneman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Amy_Cotton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Amy_Gale - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Amy_Pascal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Amy_Redford - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Amy_Smart - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Amy_Yasbeck - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anastasia_Kelesidou - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anastasia_Myskina - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anatoliy_Kinakh - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ana_Claudia_Talancon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ana_Guevara - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ana_Isabel_Sanchez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ana_Palacio - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ana_Paula_Gerard - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ana_Sebastiao - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anderson_Varejao - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anders_Ebbeson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anders_Fogh_Rasmussen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andreas_Vinciguerra - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrea_Bocelli - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrea_De_Cruz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrea_Kiser - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrea_Yates - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrei_Konchalovsky - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrei_Mikhnevich - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrei_Nikolishin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andres_DAlessandro - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andres_Manuel_Lopez_Obrador - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andres_Pastrana - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrew_Bernard - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrew_Bunner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrew_Caldecott - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrew_Cuomo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrew_Fastow - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrew_Firestone - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrew_Gilligan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrew_Jarecki - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrew_Luster - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrew_Niccol - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrew_Sabey - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrew_Shutley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrew_Weissmann - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrew_Wetzler - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andre_Agassi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andre_Bucher - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andre_Lange - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andre_Smith - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andre_Techine - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andrzej_Tyszkiewicz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andy_Benes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andy_Bryant - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andy_Dick - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andy_Garcia - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andy_Graves - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andy_Griffith - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andy_Griggs - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andy_Hebb - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andy_Lau - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andy_Madikians - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andy_North - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andy_Perez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andy_Roddick - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andy_Rooney - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andy_Warhol - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Andy_Wisecarver - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anette_Hosoi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed AnFernce_Negron - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Angela_Alvarado_Rosa - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Angela_Bassett - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Angela_Lansbury - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Angela_Mascia-Frye - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Angela_Merkel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Angelica_Romero - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Angelina_Jolie - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Angelo_Genova - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Angelo_Reyes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Angel_Lockward - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Angel_Maza - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Angie_Arzola - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Angie_Martinez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anibal_Ibarra - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anil_Ramsook - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anita_DeFrantz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anja_Paerson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anjum_Hussain - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anna_Chicherova - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anna_Faris - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anna_Jones - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anna_Kournikova - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anna_Nicole_Smith - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anneli_Jaatteenmaki - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Annette_Bening - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Annette_Lu - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anne_Cavers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anne_Donovan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anne_Heche - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anne_Krueger - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anne_McLellan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anne_ONeil - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Annie-Jeanne_Reynaud - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Annie_Chaplin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Annie_Machon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Annika_Sorenstam - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ann_Godbehere - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ann_Landers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ann_Morgan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ann_Veneman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Antanas_Valionis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anthony_Carter - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anthony_Corso - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anthony_Ervin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anthony_Fauci - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anthony_Garotinho - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anthony_Hazen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anthony_Hopkins - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anthony_LaPaglia - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anthony_Lee_Johnson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anthony_Mazur - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anthony_Pico - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anthony_Pisciotti - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anthony_Principi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anthony_Rackauckas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anthony_Scott_Miller - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Antje_Buschschulte - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Antonio_Banderas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Antonio_Bernardo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Antonio_Cassano - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Antonio_Catania - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Antonio_Elias_Saca - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Antonio_Palocci - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Antonio_Trillanes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Antony_Leung - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anton_Balasingham - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Antwun_Echols - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anwar_Ibrahim - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Anzori_Kikalishvili - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aparna_Pillai - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aram_Adler - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Arantxa_Sanchez-Vicario - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aretha_Franklin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Arianna_Huffington - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ariel_Sharon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Arie_Haan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Arif_Mardin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ari_Bousbib - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ari_Fleischer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Arlen_Specter - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Armando_Avila_Panchame - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Armando_Calderon_Sol - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Armando_Carrillo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Armand_Sargen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Arminio_Fraga - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Arnaud_Clement - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Arnaud_Lagardere - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Arnie_Boehm - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Arnoldo_Aleman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Arnold_Palmer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Arnold_Schwarzenegger - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Arnold_Scott - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aron_Ralston - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Arsinee_Khanjian - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Arthur_Johnson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Arthur_Martinez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Artieas_Shanks - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Arturo_Gatti - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Art_Cooper - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Art_Hoffmann - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Art_Howe - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Art_Lopez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Arye_Mekel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Asa_Hutchinson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ascencion_Barajas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ashanti - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ashlea_Talbot - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ashley_Judd - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ashley_Olsen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ashley_Postell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ashraf_Alasmar - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ashraf_Ghani - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ashton_Kutcher - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Asif_Ali_Zardari - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Asif_Hanif - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Askar_Akayev - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Asmaa_Assad - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Assad_Ahmadi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Astou_Ndiaye-Diatta - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Astrid_Betancourt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Astrid_Eyzaguirre - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Atal_Bihari_Vajpayee - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ataollah_Mohajerani - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Atiabet_Ijan_Amabel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Atom_Egoyan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Atsushi_Sato - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Audrey_Lacroix - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Audrey_Sauret - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Augustin_Calleri - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Augusto_Pinochet - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Augusto_Roa_Bastos - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Aung_San_Suu_Kyi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Austin_Kearns - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Avril_Lavigne - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Azmi_Bishara - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Azra_Akin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Babe_Ruth - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Baburam_Bhattari - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bak_Chang-Ryun - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barbara_Bach - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barbara_Becker - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barbara_Bodine - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barbara_Boxer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barbara_Brezigar - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barbara_De_Brun - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barbara_Esbin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barbara_Felt-Miller - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barbara_Roberts - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barbara_Walters - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barbora_Strycova - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barbra_Streisand - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barrett_Jackman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barry_Alvarez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barry_Bonds - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barry_Collier - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barry_Diller - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barry_Ford - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barry_Hinson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barry_Nakell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barry_Switzer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barry_Williams - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barry_Zito - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bartosz_Kizierowski - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bart_Freundlich - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bart_Hendricks - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Barzan_al-Tikriti - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Basdeo_Panday - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bashar_Assad - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Baz_Luhrmann - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed BB_King - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Beatrice_Dalle - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Beatriz_Merino - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Beecher_Ray_Kirby - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Begum_Khaleda_Zia - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bela_Karolyi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Benazir_Bhutto - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Benedita_da_Silva - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Benicio_Del_Toro - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Benito_Santiago - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Benjamin_Bratt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Benjamin_Franklin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Benjamin_Martinez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Benjamin_McKenzie - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Benjamin_Netanyahu - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Benjamin_Neulander - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ben_Affleck - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ben_Betts - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ben_Braun - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ben_Broussard - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ben_Cahoon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ben_Chandler - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ben_Cohen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ben_Curtis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ben_Davis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ben_Glisan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ben_Howland - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ben_Kingsley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ben_Lee - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ben_Stein - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ben_Wallace - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bernadette_Peters - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bernardo_Segura - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bernard_Ebbers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bernard_Giraudeau - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bernard_Kerik - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bernard_Landry - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bernard_Law - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bernard_Lord - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bernard_Siegel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bernice_Wong - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bertie_Ahern - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bertrand_Bonello - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bertrand_Delanoe - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Beth_Blough - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Beth_Jones - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Betsy_Coffin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Betsy_Smith - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bettina_Rheims - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Betty_Garrison - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Betty_Williams - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Beyonce_Knowles - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bianca_Jagger - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bijan_Darvish - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bijan_Namdar_Zangeneh - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bilal_Erdogan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Biljana_Plavsic - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Billy_Andrade - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Billy_Beane - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Billy_Bob_Thornton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Billy_Boyd - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Billy_Crawford - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Billy_Crystal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Billy_Donovan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Billy_Edelin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Billy_Gilman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Billy_Graham - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Billy_Joel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Billy_Rork - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Billy_Sollie - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Billy_Tibbets - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Belichick - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Bradley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Butler - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Byrne - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Callahan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Carmody - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Cartwright - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Clancy - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Clinton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Curry - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Doba - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Duffey - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Elliott - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Fennelly - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Frist - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Gates - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Graham - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Guerin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Herrion - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Hughes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_King - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Kollar - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Kong - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Lerach - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Maher - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Mauldin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_McBride - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Nelson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_OReilly - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Parcells - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Parsons - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Paxton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Pryor - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Rainer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Readdy - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Richardson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Self - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Simon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Sizemore - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Stapleton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Stein - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bill_Walton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bing_Crosby - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Binyamin_Ben-Eliezer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bison_Dele - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bixente_LIzarazu - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed BJ_Habibie - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Blas_Ople - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Blythe_Danner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Blythe_Hartley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bobby_Bowden - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bobby_Goldwater - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bobby_Jackson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bobby_Kielty - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bobby_Robson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bobo_Balde - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Alper - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Beauprez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Bowlsby - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Cantrell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Colvin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Crippen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Curtis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Dole - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Eskridge - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Ferguson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Geldof - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Goldman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Graham - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Guccione - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Hartley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Hayes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Herz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Holden - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Hope - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Huggins - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Iger - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Krueger - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Melvin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Menendez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Newhart - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Petrino - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Riley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Stoops - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Sulkin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Taft - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bob_Wright - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bode_Miller - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bonnie_Fuller - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bonnie_Hunt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bono - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Boris_Becker - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Boris_Berezovsky - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Boris_Henry - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Boris_Jordan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Boris_Trajkovski - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Boris_Yeltsin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Boutros_Boutros_Ghali - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bo_Pelini - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bo_Ryan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brady_Rodgers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brad_Alexander_Smith - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brad_Banks - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brad_Brownell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brad_Garrett - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brad_Gushue - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brad_Johnson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brad_Miller - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brad_Pitt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brad_Russ - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brad_Smith - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brad_Wilk - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brajesh_Mishra - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brandon_Boyd - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brandon_Fails - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brandon_Hammond - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brandon_Inge - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brandon_Jones - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brandon_Knight - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brandon_Larson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brandon_Lloyd - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brandon_Robinson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brandon_Spann - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brandon_Webb - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Branko_Crvenkovski - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brawley_King - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brendan_Fraser - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brendan_Gaughan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brendan_Hansen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brendan_Stai - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brenda_Magana - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brenda_van_Dam - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brenda_Wilson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brennon_Leighton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brent_Coles - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brett_Boone - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brett_Hawke - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brett_Hull - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brett_Perry - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Billick - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Campbell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Cashman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Clemens - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Cook - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Cowen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_De_Palma - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Florence - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Grazier - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Gregory - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Griese - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Heidik - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Henson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Jordan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Kerr - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Lara - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_McIntyre - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Meadors - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Mulroney - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Olson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Pavlich - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Scalabrine - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Schneider - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_StPierre - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Van_Dusen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Weaver - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Wells - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brian_Williams - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bridgette_Wilson-Sampras - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bridget_Fonda - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brigitte_Boisselier - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Britney_Spears - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brittany_Snow - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brock_Berlin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bronson_Arroyo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brooke_Adams - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brooke_Gordon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brooke_Shields - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Brook_Robinson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bruce_Arena - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bruce_Gebhardt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bruce_Lunsford - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bruce_Paltrow - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bruce_Springsteen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bruce_Van_De_Velde - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bruce_Weber - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bruce_Willis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bruna_Colosio - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bruno_Junquiera - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bryant_Young - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bryan_Adams - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bryan_Chui - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bryan_Cooley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bryan_Murray - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bryan_Thomas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bryce_Carmine - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Buck_Rodgers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Buddy_Ryan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Budd_Schulberg - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bud_Selig - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Buford_Blount - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bulent_Ecevit - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Bustam_A_Zedan_Aljanabi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Butch_Davis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Buzz_Hargrove - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Byron_Scott - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cabas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Caio_Blat - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Calbert_Cheaney - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Calista_Flockhart - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Calvin_Harrison - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Calvin_Joseph_Coleman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cameron_Diaz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Camilla_Parker_Bowles - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Camille_Colvin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Camille_Lewis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Camryn_Manheim - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Candace_Sutton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Candice_Beatty - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Candice_Bergen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Candie_Kung - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carey_Lowell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carina_Lau_Ka-ling - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carin_Koch - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cari_Davis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carla_Del_Ponte - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carla_Gay_Balingit - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carla_Gugino - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carla_Moreno - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carla_Myers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carla_Sullivan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carla_Tricoli - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Alberto - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Alberto_Parreira - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Arroyo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Barra - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Barragan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Beltran - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Bianchi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_De_Abreu - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Fasciolo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Ghosn - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Iturgaitz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Juarez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Lordkipanitse - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Manuel_Pruneda - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Menem - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Mesa - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Moya - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Ortega - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Paternina - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Queiroz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Quintanilla_Schmidt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Ruckauf - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Ruiz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Salinas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Savedra - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlos_Vives - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlo_Ancelotti - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlo_Azeglio_Ciampi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlton_Baugh - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carlton_Dotson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carly_Fiorina - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carly_Gullickson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carl_Levin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carl_Pope - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carl_Reiner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carmen_Electra - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carolina_Barco - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carolina_Kluft - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carolina_Moraes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Caroline_Dhavernas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Caroline_Kennedy - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Caroline_Link - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carolyn_Dawn_Johnson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carolyn_Kuhl - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carol_Burnett - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carol_Carmody - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carol_Moseley_Braun - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carol_Niedermayer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carol_Williams - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carrie-Anne_Moss - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carroll_Weimer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carson_Daly - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Carson_Palmer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Casey_Crowder - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Casey_Mears - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cassandra_Heise - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cass_Ballenger - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Casy_Preslar - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cate_Blanchett - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Catherine_Bell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Catherine_Deneuve - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Catherine_Donkers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Catherine_Ndereba - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Catherine_Woodard - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Catherine_Zeta-Jones - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cathryn_Crawford - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cathy_Chisholm - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cathy_Cunningham - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cathy_Freeman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Catriona_Le_May_Doan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cecile_de_France - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cecilia_Bolocco - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cecilia_Chang - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cecilia_Cheung - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cedric_Benson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Celia_Cruz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Celine_Dion - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Celso_Amorim - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Celso_Lafer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cemil_Cicek - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cesar_Gaviria - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cesar_Maia - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chadha_Gurinder - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chakib_Khelil - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chance_Mock - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chanda_Rubin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chandrika_Kumaratunga - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chang_Dae-whan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chang_Jae_On - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chang_Saio-yue - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chang_Sang - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chang_Tso - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chante_Jawan_Mallard - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chan_Choi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chan_Gailey - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chan_Ho_Park - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charla_Moye - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charlene_Barshefsky - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charles_Bell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charles_Bronson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charles_Chandler_IV - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charles_Cope - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charles_Grassley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charles_Holzner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charles_Ingram - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charles_Kartman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charles_Lebois - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charles_Mathews - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charles_Moose - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charles_Pickering - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charles_Pouty - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charles_Richardson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charles_Rogers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charles_Schumer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charles_Tannok - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charles_Taylor - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charley_Armey - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charlie_Coles - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charlie_Deane - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charlie_Garner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charlie_Hunnam - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charlie_Sheen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charlie_Williams - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charlie_Zaa - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charlize_Theron - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charlotte_Casiraghi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charlotte_Chambers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charlotte_Church - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charlotte_Rampling - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charlton_Heston - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Charmaine_Crooks - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chawki_Armali - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cha_Yung-gu - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chea_Sophara - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chelsea_Clinton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chen_Kaige - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chen_Liang_Yu - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chen_Shui-bian - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chen_Tsai-chin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cherie_Blair - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cherry_Jones - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cheryl_Ford - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cheryl_Hines - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cheryl_James - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cheryl_Little - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cheryl_Tiegs - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chhouk_Rin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chick_Hearn - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chin-Feng_Chen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chin-Hui_Tsao - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chip_Burrus - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chip_Ganassi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chip_Knight - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chistian_Stahl - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chita_Rivera - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chloe_Sevigny - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Choi_Sung-hong - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Choi_Yun-yong - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chok_Tong_Goh - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cho_Myung-kyun - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christiane_Wulff - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christian_Bale - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christian_Fittipaldi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christian_Gimenez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christian_Lacroix - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christian_Lirette - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christian_Longo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christian_Malcolm - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christian_Olsson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christian_Patino - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christian_Von_Wernich - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christian_Wulff - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christina_Aguilera - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christina_Sawaya - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christine_Arron - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christine_Baumgartner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christine_Ebersole - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christine_Gregoire - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christine_Rau - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christine_Todd_Whitman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christopher_Amolsch - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christopher_Conyers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christopher_Matero - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christopher_Patten - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christopher_Reeve - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christopher_Russell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christopher_Speer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christopher_Walken - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christopher_Whittle - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christoph_Daum - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christy_Ferer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Christy_Turlington - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Andrews - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Bell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Byrd - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Cirino - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Claiborne - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Columbus - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Cookson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Cooper - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Cornell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Crocker - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Dodd - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Forsyth - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Gratton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Hernandez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Klein - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Kolanas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Matthews - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Moore - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Neil - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Noth - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Penn - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Pronger - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Reitsma - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Rock - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Simon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Swecker - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Terry - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Thomas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Tucker - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chris_Whitney - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chuanyun_Li - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chuck_Amato - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chuck_Bednarik - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chuck_Eidson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chuck_Finley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chuck_Hagel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chuck_Woolery - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chuck_Yeager - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chung_Mong-hun - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chung_Mong-joon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Chyung_Dai-chul - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ciaran_Hinds - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cindy_Crawford - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cindy_Klassen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cindy_Margolis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cindy_Moll - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cindy_Taylor - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cindy_Zagorski - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ciro_Gomes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Claire_Danes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Claire_De_Gryse - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Claire_Hentzen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Claire_Leger - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Claire_Tomalin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Clara_Harris - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Clare_Latimer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Clare_Short - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Clark_Randt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Claudette_Robinson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Claude_Jorda - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Claudia_Cardinale - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Claudia_Coslovich - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Claudia_Pechstein - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Claudia_Schiffer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Claudine_Farrell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Claudio_Abbado - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Claudio_Lopez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Claudio_Ranieri - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Clay_Aiken - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Clay_Campbell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Clemente_de_la_Vega - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Clifford_Etienne - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Clifford_Robinson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cliff_Ellis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Clint_Eastwood - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Clint_Howard - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Clint_Lamebear - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Clive_Lloyd - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Clive_Woodward - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Coco_dEste - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Coleen_Rowley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cole_Chapman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Colin_Campbell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Colin_Cowie - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Colin_Farrell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Colin_Jackson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Colin_Montgomerie - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Colin_Phillips - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Colin_Powell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Colin_Prescot - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Colleen_Atwood - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Colleen_Donovan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Colleen_Jones - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Colleen_OClair - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Colleen_Ryan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Collis_Temple_III - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Columba_Bush - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Compay_Segundo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Conan_OBrien - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Conchita_Martinez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Condoleezza_Rice - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Connie_Chung - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Connie_Freydell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Conrad_Black - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Constance_Marie - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cora_Cambell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Coretta_Scott_King - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Corey_Maggette - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Corinna_Harfouch - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Corinne_Coman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cori_Enghusen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Corliss_Williamson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cosmo_Iacavazzi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Costas_Simitis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Courtney_Cox - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Courtney_Love - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Craig_Burley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Craig_David - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Craig_Doblin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Craig_Fitzgibbon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Craig_MacTavish - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Craig_Morgan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Craig_OClair - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Craig_Wilson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Crandall_Bowles - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Crispin_Glover - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cristiano_da_Matta - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cristian_Barros - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cristina_Fernandez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cristina_Kirchner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cristina_Saralegui - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cristina_Torrens_Valero - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cruz_Bustamante - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cuba_Gooding_Jr - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Curtis_Joseph - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Curtis_Rodriguez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Curtis_Strange - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Curt_Weldon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cyndi_Thompson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cynthia_Nixon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Cynthia_Rowley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dagmar_Dunlevy - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daisy_Fuentes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dai_Bachtiar - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dai_Chul_Chyung - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daja_Bedanova - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dalai_Lama - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dale_Bosworth - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dale_Earnhardt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dale_Earnhardt_Jr - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dalia_Rabin-Pelosoff - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Damarius_Bilbo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Damon_Dash - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Damon_Stoudamire - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Damon_van_Dam - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dana_Vollmer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed DAngelo_Jimenez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniela_Cicarelli - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniela_Hantuchova - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniele_Bergamin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniele_Hypolito - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniele_Nardello - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Danielle_Spencer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniell_Sunjata - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniel_Barenboim - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniel_Bruehl - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniel_Chin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniel_Coats - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniel_Comisso_Urdaneta - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniel_Darnell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniel_Day-Lewis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniel_Kurtzer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniel_Montenegro - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniel_Montgomery - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniel_Ortega - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniel_Osorno - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniel_Patrick_Moynihan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniel_Pearl - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniel_Radcliffe - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniel_Rouse - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniel_Scioli - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daniel_Zelman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Danis_Tanovic - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Danny_Ainge - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Danny_Avalon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Danny_Elfman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Danny_Glover - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Danny_Green - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Danny_Morgan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dany_Heatley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dan_Ackroyd - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dan_Bartlett - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dan_Boyle - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dan_Bylsma - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dan_Dickau - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dan_Duquette - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dan_Guerrero - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dan_Kellner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dan_LaCoutre - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dan_Monson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dan_Morales - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dan_Prinster - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dan_Quayle - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dan_Reeves - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dan_Snyder - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dan_Wheldon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Darcy_Regier - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Darin_Erstad - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dario_Camuffo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dario_Franchitti - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dariusz_Michalczewski - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Darko_Milicic - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Darla_Moore - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Darlene_Garrettson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Darrell_Dickey - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Darrell_Issa - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Darrell_Porter - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Darrell_Royal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Darren_Campel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Darren_Clarke - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Darryl_McDaniels - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Darryl_Stingley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Darvis_Patton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daryl_Hannah - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daryl_Jones - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daryl_Parks - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daryl_Sabara - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Daryl_Smith - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Davey_Johnson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dave_Barr - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dave_Campo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dave_Johnson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dave_Lewis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dave_Matthews - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dave_McGinnis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dave_McNally - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dave_McNealey - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dave_Odom - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dave_Potter - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dave_Ragone - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dave_Robertson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dave_Tucker - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dave_Wannstedt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dave_Williams - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Alpay - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Anderson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Arquette - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Ballantyne - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Beckham - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Bell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Bisbal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Blaine - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Bowie - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Braley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Brent - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Brinkley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Brown - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Canary - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Caraway - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Carradine - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Caruso - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Chase - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Collenette - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Coulthard - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Dewayne_Williams - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Dewhurst - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Dodge - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Donohue - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Dorfman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Duke - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Duval - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Eldon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Gest - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Glenn - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Hannay - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Hanson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Hasselhoff - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Heyman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Heymann - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Hilt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Ho - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Howard - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Hyde_Pierce - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Kelley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Kelly - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Leahy - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_McCallum - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_McCullough - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_McKiernan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Millar - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Modell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Montoya - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Myers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Nalbandian - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Obey - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Oh - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Provost - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Przybyszewski - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Rivkin_Jr - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Scott_Morris - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Shayler - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Sibleyk - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Siegel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Sousa - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Spade - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Stern - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Suazo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Surrett - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Tornberg - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Trimble - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Welch - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Wells - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Westerfield - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Wolf - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed David_Zeplowitz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Davis_Love_III - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dawna_LoPiccolo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dawn_Staley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dean_Barker - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dean_Barkley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dean_Jacek - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dean_Sheremet - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Debbie_Allen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Debbie_Reynolds - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Debra_Brown - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Debra_Messing - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Debra_Rose - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Debra_Shank - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Debra_Yang - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Deb_Santos - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Deece_Eckstein - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Deena_Burnett - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Deepa_Mehta - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Della_Clara - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Delphine_Chuillot - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Demetrin_Veal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Demetrius_Ferraciu - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Demi_Moore - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Denise_Johnson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Denise_Locke - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Denise_van_Outen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Denis_Coderre - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Denis_Fassou-Nguesso - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Deniz_Baykal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dennis_Archer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dennis_Erickson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dennis_Franchione - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dennis_Hastert - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dennis_Johnson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dennis_Kozlowski - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dennis_Kucinich - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dennis_Miller - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dennis_Oswald - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dennis_Powell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Denys_Arcand - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Denzel_Washington - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dereck_Whittenburg - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Derek_Abney - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Derek_Bond - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Derek_Jeter - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Derek_King - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Derek_Lowe - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Derek_Parra - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Derian_Hatcher - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Derrick_Battie - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Derrick_Rodgers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Derrick_Taylor - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Desiree_Lemosi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Desiree_McKenzie - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Desmon_Farmer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Des_Brown - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Devin_Harris - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dewayne_White - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dexter_Jackson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Diana_Krall - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Diana_Munz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Diana_Renee_Valdivieso_Dubon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Diana_Ross - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Diana_Silvius - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Diana_Taurasi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Diana_Taylor - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Diane_Green - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Diane_Ladd - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Diane_Lane - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dianne_Feinstein - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dianne_Reeves - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dick_Armey - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dick_Bennett - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dick_Cheney - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dick_Clark - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dick_Devine - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dick_Jauron - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dick_Latessa - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dick_Posthumus - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dick_Smothers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dick_Vermeil - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Didier_Defago - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Diego_Armando_Maradona - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Diego_Colorado - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Diego_Diego_Lerman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dieter_Holzer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dieter_Zetsche - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dimitar_Berbatov - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dimitri_Perricos - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dinah_Turner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dinora_Rosales - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dino_de_Laurentis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dino_Risi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Din_Samsudin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dionigi_Tettamanzi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dionne_Warwick - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dionyssis_Georgiadis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dion_Glover - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dirk_Kempthorne - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dita_Von_Tesse - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Djabir_Said-Guerni - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Doc_Rivers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dolly_Parton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dolma_Tsering - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dominick_Dunne - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dominic_Monaghan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dominik_Garcia-Lorido - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dominik_Hrbaty - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dominique_de_Villepin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dominique_Perben - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Donald_Anderson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Donald_Carty - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Donald_Evans - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Donald_Fehr - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Donald_Hays - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Donald_Keck - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Donald_Keyser - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Donald_Pettit - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Donald_Regan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Donald_Rumsfeld - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Donald_Trump - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Donatella_Versace - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Donna_Barrera - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Donna_Brazile - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Donna_Morrissey - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Donna_Ralston - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Donna_Shalala - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Donna_Walker - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Donnie_Brennan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Donny_Osmond - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Don_Boudria - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Don_Carcieri - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Don_Flanagan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Don_Henley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Don_Hewitt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Don_King - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Don_Lake - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Don_Matthews - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Don_Meredith - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Don_Nickles - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Don_Siegelman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dora_Bakoyianni - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Doris_Roberts - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Doris_Schroeder - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dorothy_Lamour - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dorothy_Loudon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dorothy_Wilson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dorthy_Moxley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dot_Helms - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Douglas_Faneuil - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Douglas_Gansler - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Douglas_Meester - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Douglas_Paal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Doug_Christie - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Doug_Collins - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Doug_Duncan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Doug_Melvin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Doug_Moe - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Doug_Racine - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Doug_Wilson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dragan_Covic - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Drew_Barrymore - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Drew_Bledsoe - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Drew_Gooden - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Duane_Barber - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Duane_Lee_Chapman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dudley_Rogers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dule_Hill - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Duncan_Fletcher - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dunn_Lampton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dustan_Mohr - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dustin_Brown - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dustin_Hoffman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dusty_Baker - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Du_Qinglin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dwain_Kyles - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dwayne_Johnson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dwayne_Wade - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dwayne_Williams - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dyab_Abou_Jahjah - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Dyana_Calub - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Earl_Campbell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Earl_Counter - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Earl_Fritts - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Earl_Scruggs - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eddie_Compass - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eddie_Fenech_Adami - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eddie_Jordan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eddie_Lewis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eddie_Lucio - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eddie_Murray - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eddie_Sutton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eddy_Hartenstein - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eddy_Merckx - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edgar_Savisaar - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edie_Falco - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edina_Batar - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edith_Masai - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edmund_Hillary - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edmund_Stoiber - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edouard_Michelin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eduardo_Chillida - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eduardo_Duhalde - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eduardo_Fischer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eduardo_Romero - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eduard_Limonov - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eduard_Shevardnadze - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edward_Albee - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edward_Arsenault - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edward_Belvin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edward_Burns - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edward_Egan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edward_Flynn - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edward_Greenspan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edward_James_Olmos - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edward_Johnson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edward_Kennedy - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edward_Lohn - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edward_Lu - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edward_Norton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edward_Said - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edward_Seaga - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edwina_Currie - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Edwin_Edwards - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ed_Book - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ed_Case - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ed_Mekertichian - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ed_Rendell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ed_Rosenthal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ed_Smart - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ed_Sullivan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ed_Wade - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Efrain_Rios_Montt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eglis_Yaima_Cruz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eileen_Coparropa - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eileen_Spina - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Einars_Repse - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ekaterina_Dmitriev - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ekke_Hard_Forberg - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eladio_Larez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elaine_Chao - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elaine_Stritch - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elena_Bereznaya - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elena_Bovina - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elena_Dementieva - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elena_de_Chavez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elena_Likhovtseva - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elena_Tihomirova - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elgin_Baylor - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eliane_Karp - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elias_Attallah - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elijah_Wood - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elijan_Ingram - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elinor_Caplan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elin_Nordegren - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eliott_Spitzer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elisabeth_Schumacher - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elisabeth_Welch - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elisha_Cuthbert - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elizabeth_Berkeley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elizabeth_Dole - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elizabeth_Hill - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elizabeth_Hurley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elizabeth_Pena - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elizabeth_Regan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elizabeth_Shue - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elizabeth_Smart - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elizabeth_Taylor - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eliza_Dushku - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eliza_Manningham-Buller - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eli_Broad - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eli_Rosenbaum - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eli_Stutsman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ellen_Barkin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ellen_DeGeneres - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ellen_Engleman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ellen_MacArthur - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ellen_Martin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ellen_Pompeo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ellen_Saracini - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elliott_Mincberg - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elmar_Brok - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elodie_Bouchez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eloy_Gutierrez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elsa_Zylberstein - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elton_John - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elva_Hsiao - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elvis_Costello - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elvis_Presley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Elvis_Stojko - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed El_Hadji_Diouf - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Emanuel_Ginobili - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Emelie_Loit - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Emile_Lahoud - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Emilio_Azcarraga_Jean - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Emilio_Botin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Emily_Mason - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Emily_Mortimer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Emily_Robison - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Emily_Stevens - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eminem - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Emmanuelle_Beart - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Emmanuelle_Jagodsinski - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Emmanuel_Filiberto - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Emmanuel_Milingo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Emma_Nicholson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Emma_Thompson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Emma_Watson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Emmit_Smith - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Emmy_Rossum - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Emyr_Jones_Parry - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Enola_Rice - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Enos_Slaughter - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Enrica_Fico - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Enrik_Vendt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Enrique_Bolanos - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Enrique_Haroldo_Gorriaran_Merlo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Enrique_Iglesias - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Enrique_Medina_Gomez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Enrique_Oliu - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Erick_Barkley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Bana - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Benet - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Christian_Olsen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Clapton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Daze - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Dubin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Fehr - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Hinske - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Idle - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Lindros - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Lloyd - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Robert_Rudolph - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Rosser - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Ryan_Donnelly - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Schacht - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Shinseki - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Snow - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Staal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Taino - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Vigouroux - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eric_Wedge - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Erika_Christensen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Erika_Harold - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Erika_Reyes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eriko_Tamura - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Erik_Morales - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Erin_Brockovich - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Erin_Hershey_Presley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Erin_Runnion - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ernesto_Zedillo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ernest_Hollings - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ernie_Els - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ernie_Eves - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ernie_Fletcher - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ernie_Grunfeld - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ernie_Harwell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ernie_Preate - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ernie_Stewart - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Erskine_Bowles - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Erwin_Abdullah - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Erwin_Mapasseng - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Esad_Landzo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Esteban_Cordoba-Velazquez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Estella_Warren - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Estelle_Morris - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ester_Canadas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Esther_Macklin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ethan_Hawke - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Etta_James - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eugene_Melnyk - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eugene_Teslovic - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eunice_Barber - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eurico_Guterres - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Evander_Holyfield - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Evan_Marriott - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Evan_Rachel_Wood - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eva_Amurri - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eva_Dimas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eva_Herzigova - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eva_Marie_Saint - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eva_Mendes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Evelyn_Lauder - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eve_Ensler - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Eve_Pelletier - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Evgeni_Plushenko - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Evie_Lazarou - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Evo_Morales - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ewan_McGregor - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed E_Clay_Shaw - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fabian_Vargas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fabiola_Zuluaga - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fabrice_Santoro - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fabricio_Oberto - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Faisal_Iqbal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Faisal_Saleh_Hayat - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fann_Wong - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Farida_Ragoonanan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Farouk_al-Sharaa - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Farouk_Kaddoumi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fatma_Kusibeh - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fatmir_Limaj - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Faye_Alibocus - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Faye_Dunaway - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Faye_Wong - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fayssal_Mekdad - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fazal-ur-Rehman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Federico_Castelan_Sayre - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Federico_Fellini - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Federico_Trillo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Feliciano_Lopez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Felicity_Huffman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Felipe_De_Borbon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Felipe_Fernandez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Felipe_Perez_Roque - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Felix_Doh - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Felix_Mantilla - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Felix_Sanchez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Felix_Trinidad - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ferenc_Madl - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fernando_Alonso - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fernando_Gonzalez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fernando_Henrique_Cardoso - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fernando_Hierro - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fernando_Leon_de_Aranoa - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fernando_Sanz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fernando_Valenzuela - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fernando_Vargas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fernando_Velardez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Festus_Mogae - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fidel_Castro - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fidel_Castro_Daiz-Balart - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Filippo_Inzaghi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Filippo_Volandri - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Filip_De_Winter - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fiona_Milne - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Flavia_Delaroli - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Flavia_Pennetta - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Florecita_Cobian - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Florencia_Kirchner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Florencia_Macri - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Flor_Montulo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Floyd_Keith - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Floyd_Mayweather - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Francesco_Totti - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frances_Fisher - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Francisco_Flores - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Francisco_Garcia - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Francisco_Maturana - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Francisco_Santos - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Francisco_Urenda - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Francis_Collins - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Francis_Crick - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Francis_Ford_Coppola - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Francis_George - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Francis_Mer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Francis_Ricciardone - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Franck_Cerutti - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Francois_Botha - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Francois_Ozon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Francois_Pienaar - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Franco_Cangele - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Franco_Dragone - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Franco_Frattini - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Franklin_Brown - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Franklin_Damann - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Franko_Simatovic - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Abagnale_Jr - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Beamer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Bell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Cassell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Coraci - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Dunham_Jr - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Griswold - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Hilldrup - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Hsieh - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Keating - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Lautenberg - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Marshall - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Murkowski - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Pallone - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Schmoekel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Shea - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Sinatra - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Solich - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Stallone - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Taylor - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Van_Ecke - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Wycheck - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frank_Zappa - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Franz_Beckenbauer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Franz_Fischler - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Franz_Gsell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Franz_Muentefering - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fran_Drescher - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Freda_Black - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Freddy_Garcia - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Freddy_Vasques_Kinchokpe - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frederick_Madden - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Frederique_van_der_Wal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fredric_Seaman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fred_Durst - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fred_Eckhard - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fred_Funk - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fred_Huff - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fred_Rogers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fred_Swan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fred_Thompson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fred_Wilpon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fruit_Chan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fujio_Cho - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Fujio_Mitarai - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gabi_Zimmer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gabriella_Bo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gabrielle_Rose - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gabrielle_Union - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gabriel_Batistuta - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gabriel_Farhi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gabriel_Hughes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gabriel_Jorge_Ferreia - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gabriel_Valdes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gael_Garcia_Bermal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gala_Leon_Garcia - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Galen_Rowell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gao_Qiang - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Garry_Alejano - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Garry_Kasparov - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Garry_McCoy - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Garry_Trudeau - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Garry_Witherall - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Garth_Drabinsky - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Bald - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Barnett - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Bauer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Bergeron - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Bettman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Carter - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Coleman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Condit - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Dellaverson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Doer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Forsee - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Gero - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Gitnick - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Leon_Ridgway - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Locke - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Marshall - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Paer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Sayler - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Sinise - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Stevens - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Williams - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gary_Winnick - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gaston_Gaudio - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gavin_Degraw - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gavyn_Arthur - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gavyn_Davies - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gene_Autry - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gene_Hackman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gene_Keady - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gene_Orza - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gene_Robinson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gene_Sauers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gennifer_Flowers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Geno_Auriemma - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gen_Meredith - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Geoffrey_Davis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Geoffrey_Rush - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Geoff_Dixon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Geoff_Hoon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Allen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Blaney - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Bovell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Brumley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Brumley_III - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Clooney - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Foreman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Galloway - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Gregan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Harrison - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_HW_Bush - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Karl - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Lopez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Lucas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Maxwell_Richards - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_McCloud - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Murphy - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Papandreou - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Pataki - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Plimpton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_P_Bush - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Robertson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Roy_Hill - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Ryan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Tenet - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_Voinovich - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed George_W_Bush - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Georgia_Giddings - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Georgina_Bardach - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Georgina_Papin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Georgi_Parvanov - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Geovani_Lapentti - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Geraldine_Chaplin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Geraldo_Rivera - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gerald_Barbarito - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gerald_Calabrese - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gerald_Fitch - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gerald_Ford - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gerald_Riley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gerardo_Gambala - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gerard_Butler - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gerard_Depardieu - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gerard_de_Cortanze - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gerard_Kleisterlee - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gerard_Tronche - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gerhard_Boekel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gerhard_Schmid - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gerhard_Schroeder - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed German_Khan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gerrit_Zalm - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gerry_Adams - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gerry_Kelly - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gerry_Parsky - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ghassan_Elashi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gholamreza_Aghazadeh - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Giancarlo_Fisichella - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gianna_Angelopoulos-Daskalaki - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Giannina_Facio - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gianni_Agnelli - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gian_Marco - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gideon_Black - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gideon_Yago - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gilberto_Rodriguez_Orejuela - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gilberto_Simoni - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gilles_Panizzi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gillian_Anderson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gil_Cates - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gil_de_Ferran - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gina_Centrello - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gina_Gershon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gina_Lollobrigida - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gina_Torres - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Giovanny_Cordoba - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gisele_Bundchen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Giselle_Estefania_Tavarelli - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Giulietta_Masina - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Giulio_Andreotti - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Giuseppe_Gibilisco - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Giuseppe_Morchio - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Glafcos_Clerides - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Glenn_Plummer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Glenn_Rivers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Glenn_Tilton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Glen_Clark - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Glen_DaSilva - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Glen_Sather - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gloria_Allred - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gloria_Gaynor - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gloria_Macapagal_Arroyo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gloria_Trevi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed GL_Peiris - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Goh_Kun - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Goldie_Hawn - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gong_Li - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gong_Ruina - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gonzalo_Barrientos - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gonzalo_Sanchez_de_Lozada - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Goran_Persson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Goran_Zivkovic - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gordana_Grubin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gorden_Tallis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gordon_Brown - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gordon_Campbell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gordon_Cooper - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gordon_Lightfoot - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gordon_McDonald - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gore_Verbinski - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gore_Vidal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Grace_Brinell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Grace_Dodd - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Grace_Kelly - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Graciano_Rocchigiani - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gracia_Burnham - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Grady_Irvin_Jr - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Grady_Little - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Graeme_Lloyd - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Graeme_Smith - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Graham_Bentley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Grant_Hackett - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Grant_Rossenmeyer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gray_Davis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gregg_Berhalter - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gregg_Popovich - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gregorio_Honasan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gregorio_Rosal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gregory_Geoffroy - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gregory_Hines - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gregory_Peck - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gregor_Gysi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Greg_Frers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Greg_Gilbert - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Greg_Hennigar - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Greg_Hodge - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Greg_Kinnear - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Greg_Kinsey - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Greg_Ostertag - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Greg_Owen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Greg_Rusedski - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gretchen_Mol - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Griffin_Colvin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gro_Harlem_Brundtland - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Guangdong_Ou_Guangyuan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Guennadi_Chipouline - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Guenter_Verheugen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Guido_Westerwelle - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Guillaume_Cannet - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Guillaume_Depardieu - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Guillaume_Soro - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Guillermo_Canas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Guillermo_Coria - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Guillermo_Monroy - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Guillermo_Ortiz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Guillermo_Ruiz_Polanco - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gunilla_Backman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gunter_Pleuger - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gustavo_Cisneros - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gustavo_Franco - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gustavo_Kuerten - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gustavo_Noboa - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gustavo_Terrazas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gus_Frerotte - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gus_Van_Sant - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Guus_Hiddink - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Guy_Hemmings - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Guy_Ritchie - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Guy_Verhofstadt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gwendal_Peizerat - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gwen_Stefani - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Gwyneth_Paltrow - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Habib_Hisham - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Habib_Rizieq - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hadley_Bilger - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Halbert_Fillinger - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Halle_Berry - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hal_Gehman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hal_McCoy - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hal_Sellers - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hal_Sutton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hamad_Bin_Isa_al-Khalifa - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hamad_Bin_Jassim - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hama_Arba_Diallo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hamid_Efendi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hamid_Karzai - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hamid_Reza_Asefi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hamzah_Haz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hamza_Atiya_Muhsen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ham_Pong-sil - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hanan_Ashrawi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hana_Makhmalbaf - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hana_Sadiq - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hana_Urushima - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hank_Aaron - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hank_Azaria - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hank_Bass - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hank_McKinnell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hank_Stram - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hannah_Stockbauer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hanns_Schumacher - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hans-Christian_Schmid - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hans_Blix - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hans_Corell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hans_Eichel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hans_Leistritz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hans_Peter_Briegel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Han_Sung_Joo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Harald_Ringstorff - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Harbhajan_Singh - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Harland_Braun - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Harold_Brown - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Harold_Scott - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Harriet_Lessy - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Harrison_Ford - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Harry_Belafonte - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Harry_Kalas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Harry_Schmidt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hartmut_Mehdorn - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Harvey_Fierstein - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Harvey_Wachsman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Harvey_Weinstein - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hasan_Wirayuda - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hashan_Tillakaratne - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hashim_Thaci - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hassanal_Bolkiah - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hassan_Nasrallah - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hassan_Wirajuda - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hatsui_Hasuike - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Haydar_Aliyev - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hayden_Panettiere - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hayley_Tullett - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Heather_Chinnock - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Heather_Locklear - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Heather_Mills - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Heather_Whitestone_McCallum - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Heather_Willson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Heath_Ledger - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hector_Babenco - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hector_Grullon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hector_Mitelman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hedayat_Amin_Arsala - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hee-Won_Han - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Heidi_Fleiss - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Heidi_Klum - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Heinrich_Wolfgang - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Heinz_Feldmann - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Heizo_Takenaka - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Helena_Schneider - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Helene_Eksterowicz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Helen_Alvare - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Helen_Clark - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Helen_Darling - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Helio_Castroneves - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Helio_Rubens_Garcia - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Helmut_Panke - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Helo_Pinheiro - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Henk_Bekedam - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Henning_Scherf - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Henrique_Meirelles - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Henri_Proglio - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Henry_Castellanos - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Henry_Hilow - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Henry_Hyde - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Henry_Kissinger - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Henry_Suazo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Herbert_Haupt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Herbie_Hancock - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Herb_Brooks - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Herb_Dhaliwal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Herb_Ritts - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Herb_Sendek - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hermando_Harton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hermann_Maier - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Herman_Edwards - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Herman_Moore - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hermes_Gamonal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hermogenes_Ebdane_Jr - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hernan_Crespo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hernan_Diaz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Herta_Daeubler-Gmelin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hestrie_Cloette - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hichiro_Naemura - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hideki_Matsui - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hideki_Sato - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hidetoshi_Nakata - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hikmat_al-Azzawi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hilary_Duff - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hilary_McKay - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hilda_Fortune - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hillary_Clinton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hilmi_Akin_Zorlu - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hilmi_Ozkok - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Himmler_Rebu - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hipolito_Mejia - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hiroki_Gomi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hiroyuki_Yoshino - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hisao_Oguchi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hisashi_Owada - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hisham_Halawi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hitomi_Soga - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hitoshi_Oshitani - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hitoshi_Tanaka - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hoda_Asfor - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Holly_Hunter - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Holly_Robinson_Peete - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hong_Myung - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hootie_Johnson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Horace_Donovan_Reid - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Horace_Newcomb - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Horacio_de_Jesus_Montoya - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Horacio_Julio_Pina - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Horst_Koehler - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hosni_Mubarak - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Howard_Dean - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Howard_Ross - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Howard_Schultz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Howard_Smith - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Howard_Stern - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Howard_Stringer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Howard_Wilkinson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hrithik_Roshan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Huang_Suey-Sheng - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Huan_Chung_Yi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hubert_Green - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hubie_Brown - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hugh_Campbell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hugh_Carey - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hugh_Grant - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hugh_Hefner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hugh_Jessiman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hugh_Miller - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hugo_Chavez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hugo_Colace - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hugo_Conte - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Humberto_Coelho - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Humberto_Espinoza - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hung_Wan-ting - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hunter_Bates - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hunter_Kemper - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hun_Sen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hushiar_Zebari - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hussam_Mohammed_Amin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hussein_Malik - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hutomo_Mandala_Putra - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hu_Jintao - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hu_Maoyuan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Hwang_Doo-yun - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Iain_Anderson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Iain_Duncan_Smith - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Iain_Richmond - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ian_Campbell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ian_Gillan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ian_Huntley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ian_Knop - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ian_McKellen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ian_Moran - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ian_Smith - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ian_Thorpe - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ian_Wilmut - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Iban_Mayo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ibrahim_Al-Marashi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ibrahim_Haddad - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ibrahim_Hilal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ibrahim_Jaafari - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ibrahim_Rugova - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Idi_Amin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ignacio_Antonio_Velasco - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ignatius_Wang - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Igor_Ivanov - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Igor_Trunov - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ilan_Goldfajn - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ilan_Ramon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ilham_Aliev - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ilie_Nastase - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Imad_Khadduri - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Imad_Moustapha - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Imam_Samudra - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Imelda_Marcos - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Imran_Khan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Imre_Kertasz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Inam-ul-Haq - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Infanta_Cristina - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Inga_Hall - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ingrid_Betancourt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Inocencio_Arias - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Intisar_Ajouri - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ion_Iliescu - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ion_Tiriac - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Iran_Brown - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ira_Einhorn - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Irene_Kahn - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Irfan_Ahmed - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Irina_Framtsova - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Irina_Lobacheva - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Irina_Yatchenko - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Irv_Nathan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Irwan_Fadzi_Idris - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Isabela_Moraes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Isabella_Rossellini - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Isabelle_Huppert - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Isabel_Orellana - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Isaiah_Washington - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ishaq_Shahryar - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Isidro_Pastor - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Islam_Karimov - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ismael_Miranda - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ismail_Abu_Shanab - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ismail_Cem - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ismail_Khan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ismail_Merchant - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Itamar_Franco - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Itzhak_Perlman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ivana_Trump - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ivan_Helguera - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ivan_Lee - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ivan_Shvedoff - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ivan_Stambolic - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Iva_Majoli - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Iveta_Benesova - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Ivo_Dubs - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Izzat_Ibrahim - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jaap_de_Hoop_Scheffer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jackie_Chan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jackie_Dennis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jackie_Sherrill - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jacky_Cheung - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jack_Goodman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jack_Grubman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jack_Knowlton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jack_LaLanne - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jack_Nicholson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jack_Osbourne - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jack_Smith - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jack_Straw - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jack_Valenti - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jack_Welch - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jacob_Frenkel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jacqueline_Edwards - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jacqueline_Gold - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jacqueline_Marris - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jacqueline_Obradors - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jacques_Chirac - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jacques_Kallis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jacques_Rogge - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jacques_Villeneuve - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jada_Pinkett_Smith - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jade_Jagger - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jafar_Umar_Thalib - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jaime_Orti - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jaime_Pressly - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jake_Brace - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jake_Gyllenhaal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jake_Plummer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jakob_Kellenberger - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jalal_Talabani - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jalen_Rose - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Baker - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Ballenger - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Barksdale - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Becker - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Blake - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Brazelton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Brosnahan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Brown - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Butts - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Caan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Cameron - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Carville - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Coburn - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Collinson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Comey - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Coviello - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Cunningham - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Dingemans - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Franco - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Gandolfini - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Gibson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Hakett - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Hallock - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Harris - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Hill - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Hoffa - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Hughes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Ivory - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Jones - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Kelly - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Kirtley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Kopp - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Layug - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Lockhart - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Maguire - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Mathis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_May - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_McGreevey - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_McMahon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_McPherson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Meeks - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Meredeth - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Morris - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Murdoch - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Parker - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Phelps - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Roberts - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Robertson_Jr - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Schultz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Sensenbrenner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Smith - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Spalding - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Traficant - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Wallack - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Watt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Wattana - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Williams - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Wolfensohn - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_W_Kennedy - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed James_Young - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jamie_Carey - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jamie_Cooke - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jamie_Dimon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jamie_Kellner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jamie_King - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jamie_Lee_Curtis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jamie_Martin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jamie_Olis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jamie_Villafane - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jamir_Miller - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jamling_Norgay - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jan-Michael_Gambill - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jana_Henke - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jana_Pittman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Janela_Jara - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Janette_Husarova - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Janet_Chandler - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Janet_Crawford - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Janet_Ecker - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Janet_Horvath - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Janet_Leigh - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Janet_Napolitano - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Janet_Thorpe - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Janez_Drnovsek - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jane_Clayson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jane_Fonda - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jane_Kaczmarek - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jane_Krakowski - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jane_Leeves - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jane_Menelaus - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jane_Pauley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jane_Riley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jane_Rooney - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jane_Russell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jane_Walker_Wood - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Janica_Kostelic - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Janice_Abreu - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Janice_Goldfinger - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Janine_Pietsch - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Janis_Ruth_Coulter - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Janusz_Kaminski - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jan_Bjoerklund - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jan_De_Bont - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jan_Paul_Miller - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jan_Petersen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jan_Peter_Balkenende - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jan_Pronk - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jan_Ullrich - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jan_van_Breda_Kolff - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jaouad_Gharib - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jaqueline_Godoy - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jaromir_Jagr - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jason_Alexander - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jason_Bentley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jason_Biggs - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jason_Campbell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jason_Clermont - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jason_Gardner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jason_Jennings - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jason_Kapono - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jason_Keep - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jason_Kidd - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jason_Lezak - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jason_Mewes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jason_Petty - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jason_Priestley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jason_Sehorn - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jason_Sorens - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jason_Statham - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jason_Vale - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jason_White - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Javier_Bardem - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Javier_Camara - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Javier_Delgado - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Javier_Saviola - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Javier_Solana - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Javier_Vargas - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Javier_Vazquez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Javier_Weber - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Javier_Zanetti - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jawad_Boulus - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jaymon_Crabb - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jayne_Yarris - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jayson_Williams - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jay_Garner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jay_Leno - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jay_Rasulo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed JC_Chasez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean-Claude_Braquet - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean-Claude_Juncker - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean-Claude_Trichet - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean-Claude_Van_Damme - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean-David_Levitte - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean-Francois_Lemounier - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean-Francois_Pontal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean-Luc_Bideau - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean-Marc_de_La_Sabliere - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean-Marc_Olive - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean-Patrick_Nazon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean-Pierre_Bemba - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean-Pierre_Raffarin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean-Rene_Fourtou - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean-Sebastien_Giguere - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeanette_Gray - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeanette_Stauffer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeane_Kirkpatrick - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeannette_Biedermann - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeanne_Anne_Schroeder - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeanne_Moreau - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean_Brumley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean_Carnahan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean_Charest - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean_Chretien - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean_Nagel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jean_Todt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeb_Bush - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jefferson_Perez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeffery_Hendren - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeffery_Strelzin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeffrey_Archer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeffrey_Ashby - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeffrey_Donaldson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeffrey_Immelt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeffrey_Jones - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeffrey_Katzenberg - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeffrey_Pfeffer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeffrey_Scott_Postell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeff_Bridges - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeff_Bzdelik - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeff_Dederian - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeff_Feldman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeff_George - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeff_Hornacek - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeff_Roehm - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeff_Schiffner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeff_Van_Gundy - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeff_Weaver - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jelena_Dokic - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jenna_Elfman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennette_Bradley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennie_Finch - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennie_Garth - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennifer_Aniston - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennifer_Capriati - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennifer_Connelly - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennifer_Furminger - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennifer_Garner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennifer_Granholm - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennifer_Gratz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennifer_Keller - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennifer_Lopez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennifer_Love_Hewitt - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennifer_McCoy - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennifer_Murray - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennifer_Pena - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennifer_Reilly - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennifer_Renee_Short - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennifer_Rodriguez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennifer_Thompson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jennifer_Tilly - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jenny_Romero - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jens_Lehmann - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jen_Bice - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jen_Schefft - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeong_Se-hyun - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jerelle_Kraus - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeremy_Fogel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeremy_Gompertz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeremy_Greenstock - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeremy_Shockey - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeremy_Wotherspoon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jeri_Ryan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jerome_Golmard - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jerome_Jenkins - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jerry_Angelo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jerry_Bruckheimer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jerry_Colangelo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jerry_Falwell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jerry_Hall - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jerry_Jones - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jerry_Lewis - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jerry_McEntee - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jerry_Oliver - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jerry_Pauley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jerry_Regier - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jerry_Rice - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jerry_Seinfeld - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jerry_Sexton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jerry_Sloan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jerry_Springer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jerry_Tarkanian - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jesper_Parnevik - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jesse_Harris - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jesse_Helms - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jesse_Jackson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jesse_James - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jesse_James_Leija - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jesse_Ventura - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jessica_Alba - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jessica_Biel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jessica_Brungo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jessica_Capshaw - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jessica_Lange - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jessica_Lynch - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jessica_Simpson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jesus_Cardenal - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jewel_Howard-Taylor - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jiang_Zemin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jia_Qinglin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jimmy_Carter - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jimmy_Gobble - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jimmy_Gurule - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jimmy_Iovine - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jimmy_Jimenez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jimmy_Kimmel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jimmy_Lee - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jimmy_Smits - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jimmy_Szymanski - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Abbott - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Ahern - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Anderson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Beattie - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Bollman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Bunning - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Calhoun - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Cantalupo - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Carrey - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Doyle - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Edmonds - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Fassel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Flaherty - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Freudenberg - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Furyk - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Greenwood - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Hahn - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Hardin - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Harrick - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Haslett - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Hendry - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Jeffords - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Kelly - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Leach - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Letten - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Nochols - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_OBrien - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Otto - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Parque - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Paxson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Piper - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Ryan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Schwarz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Spinoza - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Sterk - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Talent - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Taylor - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Thome - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Tressel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Wall - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Wessling - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Wong - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jim_Zorn - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jiri_Novak - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed JJ_Redick - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed JK_Rowling - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joanna_Poitier - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joanne_Duquette - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joanne_Woodward - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joan_Claybrook - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joan_Collins - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joan_Dangerfield - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joan_Jett - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joan_Laporta - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joao_Rocha - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joaquim_Levy - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joaquim_Rodriguez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joaquin_Phoenix - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joaquin_Sanchez - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Job_Cohen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jodie_Foster - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jodie_Henry - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jodie_Kidd - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jody_Richards - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joel_Gallen - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joel_Todd - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joerg_Haider - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joey_Buttafuoco - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joey_Harrington - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joey_Mantia - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Calzaghe - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Carnahan - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Cocker - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Cravens - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Crede - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Darrell - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_DeLamielleure - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Dicaro - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Dumars - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Finley - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Friedberg - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Garner - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Gatti - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Glover - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Leonard - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Lieberman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Mantegna - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Mantello - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Mendes - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Metz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Nichols - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Pantoliano - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Paterno - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Plumeri - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Strummer - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Torre - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Joe_Vandever - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Johannes_Rau - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Johan_Bruyneel - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Abizaid - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Allen_Muhammad - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Anderson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Ashcroft - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Baldacci - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Banko - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Barnett - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Belushi - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Blaney - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Bolton - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Bond - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Brady - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Burkett - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Burnett - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Connolly - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Coomber - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Cornyn - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Cruz - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Cusack - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Dallager - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Daly_Jr - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Danforth - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Darby - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Duprey - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Eastman - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Eder - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Edwards - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Elway - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Engler - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Fenn - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_Ferguson - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed John_F_Kennedy_Jr - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jo_Dee_Messina - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed Jo_Joong-hyon - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed train - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n",
      "Processed val - 0 training images, 0 validation images.\n",
      "Dataset split into training and validation sets successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Paths\n",
    "original_dir = r'D:\\Coding Projects\\CNN (face recog)\\lfw-deepfunneled'  # The original dataset path\n",
    "train_dir = r'D:\\Coding Projects\\CNN (face recog)\\lfw-deepfunneled\\train'  # Path to save the training images\n",
    "val_dir = r'D:\\Coding Projects\\CNN (face recog)\\lfw-deepfunneled\\val'  # Path to save the validation images\n",
    "\n",
    "# Create the train and validation directories if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over each person's folder in the original directory\n",
    "for person in os.listdir(original_dir):\n",
    "    person_dir = os.path.join(original_dir, person)\n",
    "\n",
    "    # Check if it's a directory (skip if not a person folder)\n",
    "    if os.path.isdir(person_dir):\n",
    "        # Create subdirectories for training and validation for this person\n",
    "        person_train_dir = os.path.join(train_dir, person)\n",
    "        person_val_dir = os.path.join(val_dir, person)\n",
    "        \n",
    "        # Create the person's subdirectories inside train and val\n",
    "        os.makedirs(person_train_dir, exist_ok=True)\n",
    "        os.makedirs(person_val_dir, exist_ok=True)\n",
    "        \n",
    "        # Get all image files in the person's folder\n",
    "        images = [img for img in os.listdir(person_dir) if img.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "        # Shuffle images for randomness\n",
    "        random.shuffle(images)\n",
    "\n",
    "        # Set the proportion for validation (in this case 80% train and 20% validation)\n",
    "        num_images = len(images)\n",
    "        num_val_images = int(0.2 * num_images)  # 20% for validation\n",
    "        num_train_images = num_images - num_val_images  # 80% for training\n",
    "\n",
    "        # Split into training and validation sets\n",
    "        train_images = images[:num_train_images]\n",
    "        val_images = images[num_train_images:]\n",
    "\n",
    "        # Move the training images to the train folder\n",
    "        for img in train_images:\n",
    "            src_path = os.path.join(person_dir, img)\n",
    "            dest_path = os.path.join(person_train_dir, img)\n",
    "            shutil.move(src_path, dest_path)\n",
    "\n",
    "        # Move the validation images to the validation folder\n",
    "        for img in val_images:\n",
    "            src_path = os.path.join(person_dir, img)\n",
    "            dest_path = os.path.join(person_val_dir, img)\n",
    "            shutil.move(src_path, dest_path)\n",
    "\n",
    "        print(f\"Processed {person} - {num_train_images} training images, {num_val_images} validation images.\")\n",
    "        print(\"Dataset split into training and validation sets successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca188fe7-53b7-4594-a17b-bbb737357d62",
   "metadata": {},
   "source": [
    "**Prepare** the newly separated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "260869cd-9fec-4b5c-b815-1420577fd3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6068 images belonging to 2711 classes.\n",
      "Found 592 images belonging to 2711 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set up the ImageDataGenerator for training data with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Rescale image pixel values to [0, 1]\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Apply only rescaling to the validation data (no augmentation)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_dir = r'D:\\Coding Projects\\CNN (face recog)\\lfw-deepfunneled\\train'\n",
    "val_dir = r'D:\\Coding Projects\\CNN (face recog)\\lfw-deepfunneled\\val'\n",
    "\n",
    "# Create generators for loading and augmenting the images\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'  # Since we are doing multi-class classification\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bf705b-11c8-483c-8333-17b9078bf06d",
   "metadata": {},
   "source": [
    "The next step is to start **training** the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "291165be-41a3-493c-892d-89867fdb8c88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Val\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Epoch 1/2\n",
      "Executing op AnonymousIteratorV3 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Pack in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_initialize_variables_1274 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m  1/189\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:14\u001b[0m 5s/step - accuracy: 0.0000e+00 - loss: 7.9199Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m  2/189\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:50\u001b[0m 2s/step - accuracy: 0.0000e+00 - loss: 7.9079 Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m  3/189\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:06\u001b[0m 2s/step - accuracy: 0.0000e+00 - loss: 7.8944Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m  4/189\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:02\u001b[0m 2s/step - accuracy: 0.0000e+00 - loss: 7.8910Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m  5/189\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:00\u001b[0m 2s/step - accuracy: 0.0012 - loss: 7.8884    Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m  6/189\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:56\u001b[0m 2s/step - accuracy: 0.0028 - loss: 7.8875Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m  7/189\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:48\u001b[0m 2s/step - accuracy: 0.0043 - loss: 7.8859Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m  8/189\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:42\u001b[0m 2s/step - accuracy: 0.0072 - loss: 7.8836Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m  9/189\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:40\u001b[0m 2s/step - accuracy: 0.0099 - loss: 7.8801Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 10/189\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:38\u001b[0m 2s/step - accuracy: 0.0123 - loss: 7.8759Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 11/189\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:33\u001b[0m 2s/step - accuracy: 0.0143 - loss: 7.8723Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 12/189\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:30\u001b[0m 2s/step - accuracy: 0.0159 - loss: 7.8686Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 13/189\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:28\u001b[0m 2s/step - accuracy: 0.0182 - loss: 7.8635Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 14/189\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:26\u001b[0m 2s/step - accuracy: 0.0204 - loss: 7.8583Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 15/189\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:26\u001b[0m 2s/step - accuracy: 0.0227 - loss: 7.8535Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 16/189\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:24\u001b[0m 2s/step - accuracy: 0.0249 - loss: 7.8481Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 17/189\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:22\u001b[0m 2s/step - accuracy: 0.0268 - loss: 7.8429Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 18/189\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:23\u001b[0m 2s/step - accuracy: 0.0284 - loss: 7.8377Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 19/189\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:22\u001b[0m 2s/step - accuracy: 0.0299 - loss: 7.8322Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 20/189\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:20\u001b[0m 2s/step - accuracy: 0.0312 - loss: 7.8265Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 21/189\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:17\u001b[0m 2s/step - accuracy: 0.0323 - loss: 7.8211Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 22/189\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:14\u001b[0m 2s/step - accuracy: 0.0332 - loss: 7.8158Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 23/189\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:12\u001b[0m 2s/step - accuracy: 0.0341 - loss: 7.8103Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 24/189\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:10\u001b[0m 2s/step - accuracy: 0.0351 - loss: 7.8045Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 25/189\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:07\u001b[0m 2s/step - accuracy: 0.0359 - loss: 7.7988Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 26/189\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:05\u001b[0m 2s/step - accuracy: 0.0365 - loss: 7.7935Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 27/189\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:04\u001b[0m 2s/step - accuracy: 0.0371 - loss: 7.7877Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 28/189\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:02\u001b[0m 2s/step - accuracy: 0.0378 - loss: 7.7819Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 29/189\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:59\u001b[0m 2s/step - accuracy: 0.0383 - loss: 7.7763Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 30/189\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:57\u001b[0m 2s/step - accuracy: 0.0389 - loss: 7.7703Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 31/189\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:54\u001b[0m 2s/step - accuracy: 0.0395 - loss: 7.7644Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 32/189\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:53\u001b[0m 2s/step - accuracy: 0.0401 - loss: 7.7588Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 33/189\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:52\u001b[0m 2s/step - accuracy: 0.0406 - loss: 7.7534Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 34/189\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:51\u001b[0m 2s/step - accuracy: 0.0411 - loss: 7.7489Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 35/189\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:49\u001b[0m 2s/step - accuracy: 0.0416 - loss: 7.7448Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 36/189\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:47\u001b[0m 2s/step - accuracy: 0.0421 - loss: 7.7408Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 37/189\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:46\u001b[0m 2s/step - accuracy: 0.0425 - loss: 7.7375Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 38/189\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:44\u001b[0m 2s/step - accuracy: 0.0429 - loss: 7.7345Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 39/189\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:43\u001b[0m 2s/step - accuracy: 0.0433 - loss: 7.7318Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 40/189\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:42\u001b[0m 2s/step - accuracy: 0.0438 - loss: 7.7289Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 41/189\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:41\u001b[0m 2s/step - accuracy: 0.0442 - loss: 7.7259Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 42/189\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:38\u001b[0m 2s/step - accuracy: 0.0446 - loss: 7.7231Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 43/189\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:36\u001b[0m 2s/step - accuracy: 0.0449 - loss: 7.7204Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 44/189\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:34\u001b[0m 2s/step - accuracy: 0.0453 - loss: 7.7172Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 45/189\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:32\u001b[0m 2s/step - accuracy: 0.0458 - loss: 7.7138Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 46/189\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:30\u001b[0m 2s/step - accuracy: 0.0461 - loss: 7.7105Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 47/189\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:28\u001b[0m 2s/step - accuracy: 0.0465 - loss: 7.7073Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 48/189\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:25\u001b[0m 2s/step - accuracy: 0.0469 - loss: 7.7042Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 49/189\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:23\u001b[0m 2s/step - accuracy: 0.0472 - loss: 7.7011Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 50/189\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:21\u001b[0m 2s/step - accuracy: 0.0475 - loss: 7.6984Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 51/189\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:18\u001b[0m 2s/step - accuracy: 0.0478 - loss: 7.6958Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 52/189\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:16\u001b[0m 2s/step - accuracy: 0.0481 - loss: 7.6930Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 53/189\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:14\u001b[0m 2s/step - accuracy: 0.0484 - loss: 7.6903Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 54/189\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:11\u001b[0m 2s/step - accuracy: 0.0487 - loss: 7.6876Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 55/189\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:09\u001b[0m 2s/step - accuracy: 0.0490 - loss: 7.6849Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 56/189\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:07\u001b[0m 2s/step - accuracy: 0.0493 - loss: 7.6825Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 57/189\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:05\u001b[0m 2s/step - accuracy: 0.0495 - loss: 7.6802Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 58/189\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:04\u001b[0m 2s/step - accuracy: 0.0498 - loss: 7.6779Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 59/189\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:03\u001b[0m 2s/step - accuracy: 0.0500 - loss: 7.6759Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 60/189\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:01\u001b[0m 2s/step - accuracy: 0.0502 - loss: 7.6738Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 61/189\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:59\u001b[0m 2s/step - accuracy: 0.0504 - loss: 7.6718Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 62/189\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:57\u001b[0m 2s/step - accuracy: 0.0506 - loss: 7.6698Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 63/189\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:55\u001b[0m 2s/step - accuracy: 0.0508 - loss: 7.6680Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 64/189\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:54\u001b[0m 2s/step - accuracy: 0.0510 - loss: 7.6661Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 65/189\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:52\u001b[0m 2s/step - accuracy: 0.0512 - loss: 7.6643Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 66/189\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:50\u001b[0m 2s/step - accuracy: 0.0514 - loss: 7.6626Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 67/189\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m4:50\u001b[0m 2s/step - accuracy: 0.0515 - loss: 7.6609Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 68/189\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m4:48\u001b[0m 2s/step - accuracy: 0.0517 - loss: 7.6592Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 69/189\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m4:46\u001b[0m 2s/step - accuracy: 0.0519 - loss: 7.6577Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 70/189\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m4:44\u001b[0m 2s/step - accuracy: 0.0521 - loss: 7.6561Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 71/189\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m4:42\u001b[0m 2s/step - accuracy: 0.0522 - loss: 7.6546Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 72/189\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m4:40\u001b[0m 2s/step - accuracy: 0.0524 - loss: 7.6531Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 73/189\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m4:38\u001b[0m 2s/step - accuracy: 0.0526 - loss: 7.6517Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 74/189\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m4:36\u001b[0m 2s/step - accuracy: 0.0528 - loss: 7.6502Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 75/189\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m4:34\u001b[0m 2s/step - accuracy: 0.0529 - loss: 7.6489Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 76/189\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4:32\u001b[0m 2s/step - accuracy: 0.0531 - loss: 7.6476Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 77/189\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4:30\u001b[0m 2s/step - accuracy: 0.0533 - loss: 7.6462Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 78/189\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4:28\u001b[0m 2s/step - accuracy: 0.0534 - loss: 7.6448Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 79/189\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4:24\u001b[0m 2s/step - accuracy: 0.0536 - loss: 7.6434Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 80/189\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4:22\u001b[0m 2s/step - accuracy: 0.0538 - loss: 7.6420Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 81/189\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4:20\u001b[0m 2s/step - accuracy: 0.0539 - loss: 7.6407Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 82/189\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4:18\u001b[0m 2s/step - accuracy: 0.0541 - loss: 7.6393Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 83/189\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4:16\u001b[0m 2s/step - accuracy: 0.0542 - loss: 7.6381Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 84/189\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4:14\u001b[0m 2s/step - accuracy: 0.0544 - loss: 7.6368Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 85/189\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4:12\u001b[0m 2s/step - accuracy: 0.0545 - loss: 7.6355Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 86/189\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m4:09\u001b[0m 2s/step - accuracy: 0.0547 - loss: 7.6342Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 87/189\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m4:07\u001b[0m 2s/step - accuracy: 0.0548 - loss: 7.6330Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 88/189\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m4:05\u001b[0m 2s/step - accuracy: 0.0550 - loss: 7.6317Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 89/189\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m4:03\u001b[0m 2s/step - accuracy: 0.0551 - loss: 7.6305Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 90/189\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m4:01\u001b[0m 2s/step - accuracy: 0.0553 - loss: 7.6292Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 91/189\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:59\u001b[0m 2s/step - accuracy: 0.0554 - loss: 7.6280Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 92/189\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:56\u001b[0m 2s/step - accuracy: 0.0555 - loss: 7.6269Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 93/189\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:54\u001b[0m 2s/step - accuracy: 0.0556 - loss: 7.6257Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 94/189\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:52\u001b[0m 2s/step - accuracy: 0.0557 - loss: 7.6247Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 95/189\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3:49\u001b[0m 2s/step - accuracy: 0.0559 - loss: 7.6236Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 96/189\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3:47\u001b[0m 2s/step - accuracy: 0.0560 - loss: 7.6225Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 97/189\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3:44\u001b[0m 2s/step - accuracy: 0.0561 - loss: 7.6214Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 98/189\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3:42\u001b[0m 2s/step - accuracy: 0.0563 - loss: 7.6203Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 99/189\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3:39\u001b[0m 2s/step - accuracy: 0.0564 - loss: 7.6192Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m100/189\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3:37\u001b[0m 2s/step - accuracy: 0.0565 - loss: 7.6182Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m101/189\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3:35\u001b[0m 2s/step - accuracy: 0.0566 - loss: 7.6172Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m102/189\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3:33\u001b[0m 2s/step - accuracy: 0.0567 - loss: 7.6163Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m103/189\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3:30\u001b[0m 2s/step - accuracy: 0.0569 - loss: 7.6153Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m104/189\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m3:28\u001b[0m 2s/step - accuracy: 0.0570 - loss: 7.6143Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m105/189\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m3:25\u001b[0m 2s/step - accuracy: 0.0571 - loss: 7.6134Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m106/189\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m3:23\u001b[0m 2s/step - accuracy: 0.0572 - loss: 7.6125Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m107/189\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m3:20\u001b[0m 2s/step - accuracy: 0.0573 - loss: 7.6117Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m108/189\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m3:18\u001b[0m 2s/step - accuracy: 0.0574 - loss: 7.6108Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m109/189\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m3:15\u001b[0m 2s/step - accuracy: 0.0575 - loss: 7.6100Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m110/189\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m3:13\u001b[0m 2s/step - accuracy: 0.0576 - loss: 7.6091Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m111/189\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m3:10\u001b[0m 2s/step - accuracy: 0.0577 - loss: 7.6083Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m112/189\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m3:08\u001b[0m 2s/step - accuracy: 0.0578 - loss: 7.6074Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m113/189\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m3:05\u001b[0m 2s/step - accuracy: 0.0579 - loss: 7.6066Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m114/189\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3:03\u001b[0m 2s/step - accuracy: 0.0580 - loss: 7.6058Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m115/189\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3:00\u001b[0m 2s/step - accuracy: 0.0581 - loss: 7.6050Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m116/189\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2:58\u001b[0m 2s/step - accuracy: 0.0582 - loss: 7.6042Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m117/189\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2:55\u001b[0m 2s/step - accuracy: 0.0583 - loss: 7.6035Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m118/189\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2:53\u001b[0m 2s/step - accuracy: 0.0584 - loss: 7.6027Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m119/189\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2:50\u001b[0m 2s/step - accuracy: 0.0584 - loss: 7.6019Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m120/189\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2:48\u001b[0m 2s/step - accuracy: 0.0585 - loss: 7.6011Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m121/189\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2:45\u001b[0m 2s/step - accuracy: 0.0586 - loss: 7.6003Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m122/189\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2:43\u001b[0m 2s/step - accuracy: 0.0587 - loss: 7.5996Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m123/189\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:40\u001b[0m 2s/step - accuracy: 0.0588 - loss: 7.5989Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m124/189\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:38\u001b[0m 2s/step - accuracy: 0.0588 - loss: 7.5982Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m125/189\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:35\u001b[0m 2s/step - accuracy: 0.0589 - loss: 7.5975Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m126/189\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:33\u001b[0m 2s/step - accuracy: 0.0590 - loss: 7.5968Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m127/189\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:31\u001b[0m 2s/step - accuracy: 0.0591 - loss: 7.5961Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m128/189\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:28\u001b[0m 2s/step - accuracy: 0.0591 - loss: 7.5954Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m129/189\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:26\u001b[0m 2s/step - accuracy: 0.0592 - loss: 7.5947Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m130/189\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:23\u001b[0m 2s/step - accuracy: 0.0593 - loss: 7.5940Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m131/189\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:21\u001b[0m 2s/step - accuracy: 0.0594 - loss: 7.5933Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m132/189\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:18\u001b[0m 2s/step - accuracy: 0.0595 - loss: 7.5926Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m133/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2:16\u001b[0m 2s/step - accuracy: 0.0595 - loss: 7.5918Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m134/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2:13\u001b[0m 2s/step - accuracy: 0.0596 - loss: 7.5911Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m135/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2:11\u001b[0m 2s/step - accuracy: 0.0597 - loss: 7.5904Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m136/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2:08\u001b[0m 2s/step - accuracy: 0.0597 - loss: 7.5897Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m137/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2:06\u001b[0m 2s/step - accuracy: 0.0598 - loss: 7.5889Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m138/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2:04\u001b[0m 2s/step - accuracy: 0.0599 - loss: 7.5882Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m139/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2:01\u001b[0m 2s/step - accuracy: 0.0599 - loss: 7.5875Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m140/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:59\u001b[0m 2s/step - accuracy: 0.0600 - loss: 7.5867Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m141/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:56\u001b[0m 2s/step - accuracy: 0.0601 - loss: 7.5860Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m142/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:54\u001b[0m 2s/step - accuracy: 0.0601 - loss: 7.5853Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m143/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:51\u001b[0m 2s/step - accuracy: 0.0602 - loss: 7.5846Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m144/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:49\u001b[0m 2s/step - accuracy: 0.0603 - loss: 7.5839Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m145/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:46\u001b[0m 2s/step - accuracy: 0.0603 - loss: 7.5832Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m146/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 2s/step - accuracy: 0.0604 - loss: 7.5826Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m147/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 2s/step - accuracy: 0.0604 - loss: 7.5819Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m148/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:39\u001b[0m 2s/step - accuracy: 0.0605 - loss: 7.5812Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m149/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:37\u001b[0m 2s/step - accuracy: 0.0606 - loss: 7.5806Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m150/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:34\u001b[0m 2s/step - accuracy: 0.0606 - loss: 7.5799Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m151/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 2s/step - accuracy: 0.0607 - loss: 7.5793Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m152/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:29\u001b[0m 2s/step - accuracy: 0.0607 - loss: 7.5787Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m153/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:27\u001b[0m 2s/step - accuracy: 0.0608 - loss: 7.5780Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m154/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:24\u001b[0m 2s/step - accuracy: 0.0608 - loss: 7.5774Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m155/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:22\u001b[0m 2s/step - accuracy: 0.0609 - loss: 7.5768Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m156/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:20\u001b[0m 2s/step - accuracy: 0.0609 - loss: 7.5762Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m157/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:17\u001b[0m 2s/step - accuracy: 0.0610 - loss: 7.5756Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m158/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:15\u001b[0m 2s/step - accuracy: 0.0610 - loss: 7.5750Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m159/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:12\u001b[0m 2s/step - accuracy: 0.0611 - loss: 7.5744Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m160/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:10\u001b[0m 2s/step - accuracy: 0.0611 - loss: 7.5738Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m161/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:07\u001b[0m 2s/step - accuracy: 0.0612 - loss: 7.5732Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m162/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:05\u001b[0m 2s/step - accuracy: 0.0612 - loss: 7.5726Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m163/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:02\u001b[0m 2s/step - accuracy: 0.0612 - loss: 7.5720Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m164/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:00\u001b[0m 2s/step - accuracy: 0.0613 - loss: 7.5714Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m165/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m58s\u001b[0m 2s/step - accuracy: 0.0613 - loss: 7.5709 Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m166/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.0614 - loss: 7.5703Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m167/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.0614 - loss: 7.5698Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m168/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.0615 - loss: 7.5692Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m169/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.0615 - loss: 7.5687Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m170/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.0615 - loss: 7.5681Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m171/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.0616 - loss: 7.5675Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m172/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.0616 - loss: 7.5670Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m173/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 0.0617 - loss: 7.5664Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m174/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m36s\u001b[0m 2s/step - accuracy: 0.0617 - loss: 7.5659Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m175/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.0617 - loss: 7.5654Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m176/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.0618 - loss: 7.5649Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m177/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m29s\u001b[0m 2s/step - accuracy: 0.0618 - loss: 7.5644Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m178/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m26s\u001b[0m 2s/step - accuracy: 0.0618 - loss: 7.5639Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m179/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m24s\u001b[0m 2s/step - accuracy: 0.0619 - loss: 7.5634Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m180/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.0619 - loss: 7.5629Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m181/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.0619 - loss: 7.5624Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m182/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0620 - loss: 7.5619Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m183/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.0620 - loss: 7.5614Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m184/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.0620 - loss: 7.5609Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m185/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.0621 - loss: 7.5604 Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m186/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.0621 - loss: 7.5599Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m187/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.0621 - loss: 7.5594Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m188/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.0621 - loss: 7.5590Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.0622 - loss: 7.5585Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DivNoNan in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DivNoNan in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousIteratorV3 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DivNoNan in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DivNoNan in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 3s/step - accuracy: 0.0622 - loss: 7.5580 - val_accuracy: 0.1806 - val_loss: 5.2307\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Epoch 2/2\n",
      "Executing op __inference_multi_step_on_iterator_1976 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m  1/189\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:07\u001b[0m 2s/step - accuracy: 0.0938 - loss: 7.1547Executing op AnonymousIteratorV3 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DivNoNan in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DivNoNan in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousIteratorV3 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Val\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_5376 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DivNoNan in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DivNoNan in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 217ms/step - accuracy: 0.0938 - loss: 7.1547 - val_accuracy: 0.1823 - val_loss: 5.1685\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=2,  # Number of epochs can be increased for better model performance (number is low because of local hardware limitations)\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b891ca00-71cf-45f8-8d09-7959e0bfea6b",
   "metadata": {},
   "source": [
    "Optionally, we can **unfreeze** the last layers of the base `general-purpose image recognition model` and recompile with a lower learning rate to **fine-tune** our result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229f822b-2739-43e2-bb0e-b988b50460eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Unfreeze the last few layers of the base model (VGG16)\n",
    "for layer in base_model.layers[-4:]:  # Fine-tune the last 4 layers\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile the model with a lower learning rate to fine-tune the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Continue training the model with fine-tuning\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=2,  # Fine-tune for a few more epochs\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfead9a-487e-4071-93a2-899155307209",
   "metadata": {},
   "source": [
    "Now we will **evaluate** our resulting model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50b2258a-ccd7-4899-b7ed-1e09fc18219c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousIteratorV3 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_multi_step_on_iterator_11409 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.0938 - loss: 4.7698Executing op __inference_multi_step_on_iterator_11409 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 2/18\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 0.1094 - loss: 4.7729Executing op __inference_multi_step_on_iterator_11409 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 3/18\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.1250 - loss: 4.7266Executing op __inference_multi_step_on_iterator_11409 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 4/18\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.1328 - loss: 4.7335Executing op __inference_multi_step_on_iterator_11409 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 5/18\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 2s/step - accuracy: 0.1388 - loss: 4.7372Executing op __inference_multi_step_on_iterator_11409 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 6/18\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 2s/step - accuracy: 0.1417 - loss: 4.7490Executing op __inference_multi_step_on_iterator_11409 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 7/18\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 2s/step - accuracy: 0.1444 - loss: 4.7546Executing op __inference_multi_step_on_iterator_11409 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 8/18\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.1459 - loss: 4.7629Executing op __inference_multi_step_on_iterator_11409 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m 9/18\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.1474 - loss: 4.7647Executing op __inference_multi_step_on_iterator_11409 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m10/18\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.1480 - loss: 4.7708Executing op __inference_multi_step_on_iterator_11409 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m11/18\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.1487 - loss: 4.7781Executing op __inference_multi_step_on_iterator_11409 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m12/18\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.1500 - loss: 4.7801Executing op __inference_multi_step_on_iterator_11409 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m13/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.1514 - loss: 4.7789Executing op __inference_multi_step_on_iterator_11409 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m14/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.1532 - loss: 4.7757 Executing op __inference_multi_step_on_iterator_11409 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m15/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 0.1548 - loss: 4.7725Executing op __inference_multi_step_on_iterator_11409 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m16/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.1559 - loss: 4.7717Executing op __inference_multi_step_on_iterator_11409 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.1571 - loss: 4.7698Executing op __inference_multi_step_on_iterator_11409 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalHasValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptionalGetValue in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1583 - loss: 4.7664Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DivNoNan in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DivNoNan in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Range in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mean in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.1594 - loss: 4.7634\n",
      "Validation Loss: 4.708479881286621\n",
      "Validation Accuracy: 0.1788194477558136\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation data\n",
    "val_loss, val_accuracy = model.evaluate(val_generator, steps=val_generator.samples // val_generator.batch_size)\n",
    "print(f'Validation Loss: {val_loss}')\n",
    "print(f'Validation Accuracy: {val_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199b21a0-5be7-42f6-b30e-5cb34f527250",
   "metadata": {},
   "source": [
    "Finally, we can display the **performance data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "240cb653-adb1-487d-9682-4a9a19780f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHFCAYAAAAaD0bAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABb/klEQVR4nO3deVxUVeMG8GdmgGFHZEcRxAVB3FHUIjWV1NLMzB0xNdPSJO1XrrmVtrm8lVgaYOaG5pJvLklumVKailn64oq4AAIqq7LMnN8fyMg4gzIIDHCf7+czH+XMufeeuYL34dxzz5EJIQSIiIiIJERu7AYQERERVTUGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgkhyZTFam18GDB5/qOHPnzoVMJivXtgcPHqyQNlQ3r7zyCiwsLHD37t1S6wwfPhympqZISUkp835lMhnmzp2r+dqQ8zdq1Ch4eXmV+VglhYeHY/Xq1TrlCQkJkMlket+rSlOmTIFMJsNLL71k1HYQVUcmxm4AUVWLjY3V+nrBggU4cOAA9u/fr1Xu5+f3VMcZO3YsevXqVa5t27Zti9jY2KduQ3UzZswYbN++HevXr8dbb72l835GRga2bduGl156CS4uLuU+TlWdv/DwcDg6OmLUqFFa5W5uboiNjUWjRo0q9fiPU1BQgLVr1wIA9uzZgxs3bqBevXpGaw9RdcMARJLTsWNHra+dnJwgl8t1yh+Vm5sLS0vLMh+nfv36qF+/frnaaGtr+8T21ES9e/eGu7s7IiMj9QagDRs24N69exgzZsxTHcfY50+pVBr93++nn35CamoqXnzxRezcuRPff/89ZsyYYdQ2lcbQny2iisBbYER6dO3aFf7+/vjtt9/QuXNnWFpaYvTo0QCA6OhoBAcHw83NDRYWFvD19cW0adOQk5OjtQ99t8C8vLzw0ksvYc+ePWjbti0sLCzQrFkzREZGatXTdwtn1KhRsLa2xsWLF9GnTx9YW1vDw8MDU6dORV5entb2169fx8CBA2FjY4M6depg+PDhOH78+BNvy5w+fRoymQwRERE67+3evRsymQw7duwAAKSmpmLcuHHw8PCAUqmEk5MTnnnmGfz666+l7l+hUCA0NBQnTpzAmTNndN6PioqCm5sbevfujdTUVLz11lvw8/ODtbU1nJ2d8fzzz+Pw4cOl7r9YabfAVq9eDR8fHyiVSvj6+mLNmjV6t583bx4CAwNRt25d2Nraom3btoiIiEDJtaO9vLzw77//4tChQ5rbpsW30kq7Bfb777+je/fusLGxgaWlJTp37oydO3fqtFEmk+HAgQOYMGECHB0d4eDggAEDBuDmzZtP/OzFIiIiYGZmhqioKHh4eCAqKgr61r7+3//+h6FDh8LFxQVKpRINGjTAyJEjtb6nbty4ofm3NjMzg7u7OwYOHKi5TVnc5oSEBK196/t3qIifLQD4888/0bdvXzg4OMDc3ByNGjVCWFgYAODw4cOQyWTYsGGDznZr1qyBTCbD8ePHy3wuqXZiACIqRVJSEkaMGIFhw4Zh165dmh6LCxcuoE+fPoiIiMCePXsQFhaGTZs2oW/fvmXa7+nTpzF16lS8++67+Omnn9CyZUuMGTMGv/322xO3LSgoQL9+/dC9e3f89NNPGD16NJYuXYpPP/1UUycnJwfdunXDgQMH8Omnn2LTpk1wcXHB4MGDn7j/Vq1aoU2bNoiKitJ5b/Xq1XB2dkafPn0AACEhIdi+fTs+/PBD7N27F9999x169OiB9PT0xx5j9OjRkMlkOqHv7NmzOHbsGEJDQ6FQKHD79m0AwJw5c7Bz505ERUXB29sbXbt2LdfYqNWrV+P111+Hr68vtmzZglmzZmHBggU6tz6BogDz5ptvYtOmTdi6dSsGDBiASZMmYcGCBZo627Ztg7e3N9q0aYPY2FjExsZi27ZtpR7/0KFDeP7555GRkYGIiAhs2LABNjY26Nu3L6Kjo3Xqjx07Fqampli/fj0+++wzHDx4ECNGjCjTZ71+/Tr27t2Ll19+GU5OTggNDcXFixd1vsdOnz6N9u3b448//sD8+fOxe/duLFq0CHl5ecjPzwdQFH7at2+Pbdu2YcqUKdi9ezeWLVsGOzs73Llzp0ztedTT/mz98ssvCAoKQmJiIpYsWYLdu3dj1qxZmkAWFBSENm3aYPny5TrH/vrrr9G+fXu0b9++XG2nWkQQSVxoaKiwsrLSKuvSpYsAIPbt2/fYbdVqtSgoKBCHDh0SAMTp06c1782ZM0c8+iPm6ekpzM3NxdWrVzVl9+7dE3Xr1hVvvvmmpuzAgQMCgDhw4IBWOwGITZs2ae2zT58+wsfHR/P18uXLBQCxe/durXpvvvmmACCioqIe+5m+/PJLAUDEx8drym7fvi2USqWYOnWqpsza2lqEhYU9dl+l6dKli3B0dBT5+fmasqlTpwoA4vz583q3KSwsFAUFBaJ79+7ilVde0XoPgJgzZ47m60fPn0qlEu7u7qJt27ZCrVZr6iUkJAhTU1Ph6elZaltVKpUoKCgQ8+fPFw4ODlrbN2/eXHTp0kVnmytXruic644dOwpnZ2eRlZWl9Zn8/f1F/fr1NfuNiooSAMRbb72ltc/PPvtMABBJSUmltrXY/PnzBQCxZ88eIYQQly9fFjKZTISEhGjVe/7550WdOnXErVu3St3X6NGjhampqTh79mypdYrbfOXKFa1yfd/HFfGz1ahRI9GoUSNx7969J7bp1KlTmrJjx44JAOL7779/7LFJGtgDRFQKe3t7PP/88zrlly9fxrBhw+Dq6gqFQgFTU1N06dIFAHDu3Lkn7rd169Zo0KCB5mtzc3M0bdoUV69efeK2MplM57fhli1bam176NAh2NjY6AzAHjp06BP3DxQ9haVUKrVu32zYsAF5eXl4/fXXNWUdOnTA6tWr8dFHH+GPP/5AQUFBmfYPFA2GTktL09xOKywsxNq1axEUFIQmTZpo6n3zzTdo27YtzM3NYWJiAlNTU+zbt69M57mk+Ph43Lx5E8OGDdO6Lenp6YnOnTvr1N+/fz969OgBOzs7zb/xhx9+iPT0dNy6dcugYwNFvXJ//vknBg4cCGtra025QqFASEgIrl+/jvj4eK1t+vXrp/V1y5YtAeCJ3ydCCM1tr549ewIAGjZsiK5du2LLli3IzMwEUDTu5tChQxg0aBCcnJxK3d/u3bvRrVs3+Pr6lv0DP8HT/GydP38ely5dwpgxY2Bubl7qMYYOHQpnZ2etXqCvvvoKTk5OZeoNpdqPAYioFG5ubjpl2dnZCAoKwp9//omPPvoIBw8exPHjx7F161YAwL179564XwcHB50ypVJZpm0tLS11/tNXKpW4f/++5uv09HS9T1CV9amqunXrol+/flizZg1UKhWAottHHTp0QPPmzTX1oqOjERoaiu+++w6dOnVC3bp1MXLkSCQnJz/xGAMHDoSdnZ3mVtuuXbuQkpKiNfh5yZIlmDBhAgIDA7Flyxb88ccfOH78OHr16lWmc1VS8W05V1dXnfceLTt27BiCg4MBAKtWrcKRI0dw/PhxzJw5E0DZ/o0fdefOHQgh9H5Pubu7a7Wx2KPfJ0qlskzH379/P65cuYLXXnsNmZmZuHv3Lu7evYtBgwYhNzdXMy7mzp07UKlUTxyon5qaWu7B/KV5mp+t1NRUAHhim5RKJd58802sX78ed+/eRWpqKjZt2oSxY8dqziVJG58CIyqFvjl89u/fj5s3b+LgwYOa30wBPHZem6rm4OCAY8eO6ZSXJZgUe/3117F582bExMSgQYMGOH78OFasWKFVx9HREcuWLcOyZcuQmJiIHTt2YNq0abh16xb27Nnz2P1bWFhg6NChWLVqFZKSkhAZGQkbGxu89tprmjpr165F165ddY6blZVV5s9RrDhM6DsHj5Zt3LgRpqam+Pnnn7XC5vbt2w0+bjF7e3vI5XIkJSXpvFc8sNnR0bHc+y+peAD7kiVLsGTJEr3vv/nmm6hbty4UCgWuX7/+2P05OTk9sU7xeXp0MH5aWpre+k/zs1XcW/WkNgHAhAkT8MknnyAyMhL3799HYWEhxo8f/8TtSBrYA0RkgOL/uB/9DfLbb781RnP06tKlC7KysrB7926t8o0bN5Z5H8HBwahXrx6ioqIQFRUFc3Pzx95Ca9CgASZOnIiePXvi5MmTZTrGmDFjoFKp8Pnnn2PXrl0YMmSI1qPQMplM5zz//fffOvM4lYWPjw/c3NywYcMGrSehrl69iqNHj2rVlclkMDExgUKh0JTdu3cPP/zwg85+y9pzZ2VlhcDAQGzdulWrvlqtxtq1a1G/fn00bdrU4M/1qDt37mDbtm145plncODAAZ1X8dOA//zzDywsLNClSxds3ry51KACFE1dcODAAZ1bdCUVP/32999/a5UX3+Isi7L+bDVt2hSNGjVCZGSkTuB6lJubG1577TWEh4fjm2++Qd++fbVuP5O0sQeIyACdO3eGvb09xo8fjzlz5sDU1BTr1q3D6dOnjd00jdDQUCxduhQjRozARx99hMaNG2P37t345ZdfAABy+ZN/71EoFBg5ciSWLFkCW1tbDBgwAHZ2dpr3MzIy0K1bNwwbNgzNmjWDjY0Njh8/jj179mDAgAFlamdAQABatmyJZcuWQQihM/fPSy+9hAULFmDOnDno0qUL4uPjMX/+fDRs2BCFhYUGnJGiz7xgwQKMHTsWr7zyCt544w3cvXsXc+fO1bkF9uKLL2LJkiUYNmwYxo0bh/T0dHzxxRd6b5u0aNECGzduRHR0NLy9vWFubo4WLVrobcOiRYvQs2dPdOvWDe+99x7MzMwQHh6Of/75Bxs2bCj3rOElrVu3Dvfv38c777yDrl276rzv4OCAdevWISIiAkuXLsWSJUvw7LPPIjAwENOmTUPjxo2RkpKCHTt24Ntvv4WNjY3m6bDnnnsOM2bMQIsWLXD37l3s2bMHU6ZMQbNmzdC+fXv4+PjgvffeQ2FhIezt7bFt2zb8/vvvZW67IT9by5cvR9++fdGxY0e8++67aNCgARITE/HLL79g3bp1WnUnT56MwMBAAND7dCNJmHHHYBMZX2lPgTVv3lxv/aNHj4pOnToJS0tL4eTkJMaOHStOnjyp89RPaU+Bvfjiizr77NKli9bTRKU9BfZoO0s7TmJiohgwYICwtrYWNjY24tVXXxW7du0SAMRPP/1U2qnQcv78eQFAABAxMTFa792/f1+MHz9etGzZUtja2goLCwvh4+Mj5syZI3Jycsq0fyGE+M9//iMACD8/P5338vLyxHvvvSfq1asnzM3NRdu2bcX27dtFaGiozlNbeMJTYMW+++470aRJE2FmZiaaNm0qIiMj9e4vMjJS+Pj4CKVSKby9vcWiRYtERESEzpNOCQkJIjg4WNjY2AgAmv3oewpMCCEOHz4snn/+eWFlZSUsLCxEx44dxX//+1+tOsVPLx0/flyrvLTPVFLr1q2Fs7OzyMvLK7VOx44dhaOjo6bO2bNnxWuvvSYcHByEmZmZaNCggRg1apS4f/++Zptr166J0aNHC1dXV2Fqairc3d3FoEGDREpKiqbO+fPnRXBwsLC1tRVOTk5i0qRJYufOnXqfAnvany0hhIiNjRW9e/cWdnZ2QqlUikaNGol3331X7369vLyEr69vqeeEpEkmhJ6ZsYio1lm4cCFmzZqFxMTECh/USlRd/f3332jVqhWWL1+ud/Zxki7eAiOqhb7++msAQLNmzVBQUID9+/fjyy+/xIgRIxh+SBIuXbqEq1evYsaMGXBzc9NZr42IAYioFrK0tMTSpUuRkJCAvLw8NGjQAB988AFmzZpl7KYRVYkFCxbghx9+gK+vLzZv3sy1xkgHb4ERERGR5PAxeCIiIpIcBiAiIiKSHAYgIiIikhwOgtZDrVbj5s2bsLGxqZDJyYiIiKjyCSGQlZUFd3f3J076ygCkx82bN+Hh4WHsZhAREVE5XLt27YlTfjAA6WFjYwOg6ATa2toauTVERERUFpmZmfDw8NBcxx+HAUiP4ttetra2DEBEREQ1TFmGr3AQNBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4XQyUiIqKnJwQg1EUvtQoQqhJ/qkt8/eDvclPA1s1ozWUAIiKi2q/44qx1YVbruTiX+FMIPRdyVYn9PLrdI1+XrFfafkoNC/rapNaz79LaX9q+n3TcspybUrYXasP+TTwCgTF7K+ffuwwYgIiIjE3vxbk8F6tSLrZCXfpF/mkvtk+8yIvHHFffdoaEFAPOjaEXZ6ocMjkgUxT9qTAzalMYgIjo8XR+C37cxdbYv1E/xcW23L9RV8CFHMLY/8oEPLw4yxUl/pQXvbTKFIBc/kidR8uetL2h+1boqfsUx9XZt579lKz36H5k8lKOW7yf0tokM/a/sobRA1B4eDg+//xzJCUloXnz5li2bBmCgoL01k1KSsLUqVNx4sQJXLhwAe+88w6WLVumU2/ZsmVYsWIFEhMT4ejoiIEDB2LRokUwNzev5E9DVe5xF9Sa+hv1E9uv7yJfiRdyXpyrh7JemB538Xnai16l7vtJgeBxF9tSwoGhYaEaXZyp8hk1AEVHRyMsLAzh4eF45pln8O2336J37944e/YsGjRooFM/Ly8PTk5OmDlzJpYuXap3n+vWrcO0adMQGRmJzp074/z58xg1ahQAlLpNlVEVAvnZj/nN0MDfGmvMb9QVse9SLuS8OFcDssf/Fqv1XkX8hizXc0GtqH0/up/y/vb9uN+QSwsLTwgSRFShZEIIo11BAgMD0bZtW6xYsUJT5uvri/79+2PRokWP3bZr165o3bq1Tg/QxIkTce7cOezbt09TNnXqVBw7dgyHDx8uU7syMzNhZ2eHjIwM2Nralv0DPUnin0BkcMXtj8pAVgEXJkO6hfUcz9hdzmUJC+X+zVzB35qJqNow5PpttB6g/Px8nDhxAtOmTdMqDw4OxtGjR8u932effRZr167FsWPH0KFDB1y+fBm7du1CaGjo0zb56ckV2l+XHAxWrt9in/KiV5YLW6V1OT8hLDzVb+Yly3hxJiIiXUYLQGlpaVCpVHBxcdEqd3FxQXJycrn3O2TIEKSmpuLZZ5+FEAKFhYWYMGGCTtAqKS8vD3l5eZqvMzMzy338x3JvC8xKLXEB58WZiIjIGIx+Y1n2SAgQQuiUGeLgwYP4+OOPER4ejpMnT2Lr1q34+eefsWDBglK3WbRoEezs7DQvDw+Pch//seRywMSMPRNERERGZrQeIEdHRygUCp3enlu3bun0Chli9uzZCAkJwdixYwEALVq0QE5ODsaNG4eZM2dCrmcw4fTp0zFlyhTN15mZmZUXgoiIiMjojNYDZGZmhnbt2iEmJkarPCYmBp07dy73fnNzc3VCjkKhgBACpY33ViqVsLW11XoRERFR7WXUx+CnTJmCkJAQBAQEoFOnTli5ciUSExMxfvx4AEU9Mzdu3MCaNWs028TFxQEAsrOzkZqairi4OJiZmcHPzw8A0LdvXyxZsgRt2rRBYGAgLl68iNmzZ6Nfv35QKBQ6bSAiIiLpMWoAGjx4MNLT0zF//nwkJSXB398fu3btgqenJ4CiiQ8TExO1tmnTpo3m7ydOnMD69evh6emJhIQEAMCsWbMgk8kwa9Ys3LhxA05OTujbty8+/vjjKvtcREREVL0ZdR6g6qrS5gEiIiKiSmPI9dvoT4ERERERVTUGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHKMHoPDwcDRs2BDm5uZo164dDh8+XGrdpKQkDBs2DD4+PpDL5QgLC9Nb7+7du3j77bfh5uYGc3Nz+Pr6YteuXZX0CYiIiKimMWoAio6ORlhYGGbOnIlTp04hKCgIvXv3RmJiot76eXl5cHJywsyZM9GqVSu9dfLz89GzZ08kJCTgxx9/RHx8PFatWoV69epV5kchIiKiGkQmhBDGOnhgYCDatm2LFStWaMp8fX3Rv39/LFq06LHbdu3aFa1bt8ayZcu0yr/55ht8/vnn+N///gdTU9NytSszMxN2dnbIyMiAra1tufZBREREVcuQ67fReoDy8/Nx4sQJBAcHa5UHBwfj6NGj5d7vjh070KlTJ7z99ttwcXGBv78/Fi5cCJVKVeo2eXl5yMzM1HoRERFR7WW0AJSWlgaVSgUXFxetchcXFyQnJ5d7v5cvX8aPP/4IlUqFXbt2YdasWVi8eDE+/vjjUrdZtGgR7OzsNC8PD49yH5+IiIiqP6MPgpbJZFpfCyF0ygyhVqvh7OyMlStXol27dhgyZAhmzpypdZvtUdOnT0dGRobmde3atXIfn4iIiKo/E2Md2NHREQqFQqe359atWzq9QoZwc3ODqakpFAqFpszX1xfJycnIz8+HmZmZzjZKpRJKpbLcxyQiIqKaxWg9QGZmZmjXrh1iYmK0ymNiYtC5c+dy7/eZZ57BxYsXoVarNWXnz5+Hm5ub3vBDRERE0mPUW2BTpkzBd999h8jISJw7dw7vvvsuEhMTMX78eABFt6ZGjhyptU1cXBzi4uKQnZ2N1NRUxMXF4ezZs5r3J0yYgPT0dEyePBnnz5/Hzp07sXDhQrz99ttV+tmIiIio+jLaLTAAGDx4MNLT0zF//nwkJSXB398fu3btgqenJ4CiiQ8fnROoTZs2mr+fOHEC69evh6enJxISEgAAHh4e2Lt3L9599120bNkS9erVw+TJk/HBBx9U2eciIiKi6s2o8wBVV5wHiIiIqOapEfMAERERERkLAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJjtEDUHh4OBo2bAhzc3O0a9cOhw8fLrVuUlIShg0bBh8fH8jlcoSFhT123xs3boRMJkP//v0rttFERERUoxk1AEVHRyMsLAwzZ87EqVOnEBQUhN69eyMxMVFv/by8PDg5OWHmzJlo1arVY/d99epVvPfeewgKCqqMphMREVENZtQAtGTJEowZMwZjx46Fr68vli1bBg8PD6xYsUJvfS8vL/znP//ByJEjYWdnV+p+VSoVhg8fjnnz5sHb27uymk9EREQ1lNECUH5+Pk6cOIHg4GCt8uDgYBw9evSp9j1//nw4OTlhzJgxZaqfl5eHzMxMrRcRERHVXkYLQGlpaVCpVHBxcdEqd3FxQXJycrn3e+TIEURERGDVqlVl3mbRokWws7PTvDw8PMp9fCIiIqr+jD4IWiaTaX0thNApK6usrCyMGDECq1atgqOjY5m3mz59OjIyMjSva9eulev4REREVDOYGOvAjo6OUCgUOr09t27d0ukVKqtLly4hISEBffv21ZSp1WoAgImJCeLj49GoUSOd7ZRKJZRKZbmOSURERDWP0XqAzMzM0K5dO8TExGiVx8TEoHPnzuXaZ7NmzXDmzBnExcVpXv369UO3bt0QFxfHW1tEREQEwIg9QAAwZcoUhISEICAgAJ06dcLKlSuRmJiI8ePHAyi6NXXjxg2sWbNGs01cXBwAIDs7G6mpqYiLi4OZmRn8/Pxgbm4Of39/rWPUqVMHAHTKiYiISLqMGoAGDx6M9PR0zJ8/H0lJSfD398euXbvg6ekJoGjiw0fnBGrTpo3m7ydOnMD69evh6emJhISEqmw6ERER1WAyIYQwdiOqm8zMTNjZ2SEjIwO2trbGbg4RERGVgSHXb6M/BUZERERU1RiAiIiISHIYgIiIiEhyGICIiIhIchiAiIiISHIYgIiIiEhyGICIiIhIchiAiIiISHIYgIiIiEhyDA5AXl5emD9/vs4SFUREREQ1hcEBaOrUqfjpp5/g7e2Nnj17YuPGjcjLy6uMthERERFVCoMD0KRJk3DixAmcOHECfn5+eOedd+Dm5oaJEyfi5MmTldFGIiIiogr11IuhFhQUIDw8HB988AEKCgrg7++PyZMn4/XXX4dMJquodlYpLoZKRERU8xhy/TYp70EKCgqwbds2REVFISYmBh07dsSYMWNw8+ZNzJw5E7/++ivWr19f3t0TERERVRqDA9DJkycRFRWFDRs2QKFQICQkBEuXLkWzZs00dYKDg/Hcc89VaEOJiIiIKorBAah9+/bo2bMnVqxYgf79+8PU1FSnjp+fH4YMGVIhDSQiIiKqaAYHoMuXL8PT0/OxdaysrBAVFVXuRhERERFVJoOfArt16xb+/PNPnfI///wTf/31V4U0ioiIiKgyGRyA3n77bVy7dk2n/MaNG3j77bcrpFFERERElcngAHT27Fm0bdtWp7xNmzY4e/ZshTSKiIiIqDIZHICUSiVSUlJ0ypOSkmBiUu6n6omIiIiqjMEBqGfPnpg+fToyMjI0ZXfv3sWMGTPQs2fPCm0cERERUWUwuMtm8eLFeO655+Dp6Yk2bdoAAOLi4uDi4oIffvihwhtIREREVNEMDkD16tXD33//jXXr1uH06dOwsLDA66+/jqFDh+qdE4iIiIiouinXoB0rKyuMGzeuottCREREVCXKPWr57NmzSExMRH5+vlZ5v379nrpRRERERJWpXDNBv/LKKzhz5gxkMhmKF5MvXvldpVJVbAuJiIiIKpjBT4FNnjwZDRs2REpKCiwtLfHvv//it99+Q0BAAA4ePFgJTSQiIiKqWAb3AMXGxmL//v1wcnKCXC6HXC7Hs88+i0WLFuGdd97BqVOnKqOdRERERBXG4B4glUoFa2trAICjoyNu3rwJAPD09ER8fHzFto6IiIioEhjcA+Tv74+///4b3t7eCAwMxGeffQYzMzOsXLkS3t7eldFGIiIiogplcACaNWsWcnJyAAAfffQRXnrpJQQFBcHBwQHR0dEV3kAiIiKiiiYTxY9xPYXbt2/D3t5e8yRYTZeZmQk7OztkZGTA1tbW2M0hIiKiMjDk+m3QGKDCwkKYmJjgn3/+0SqvW7durQk/REREVPsZFIBMTEzg6enJuX6IiIioRjP4KbBZs2Zh+vTpuH37dmW0h4iIiKjSGTwI+ssvv8TFixfh7u4OT09PWFlZab1/8uTJCmscERERUWUwOAD179+/EppBREREVHUq5Cmw2oZPgREREdU8lfYUGBEREVFtYPAtMLlc/thH3vmEGBEREVV3Bgegbdu2aX1dUFCAU6dO4fvvv8e8efMqrGFERERElaXCxgCtX78e0dHR+Omnnypid0bFMUBEREQ1j1HGAAUGBuLXX3+tqN0RERERVZoKCUD37t3DV199hfr161fE7oiIiIgqlcFjgB5d9FQIgaysLFhaWmLt2rUV2jgiIiKiymBwAFq6dKlWAJLL5XByckJgYCDs7e0rtHFERERElcHgW2CjRo1CaGio5hUSEoJevXqVO/yEh4ejYcOGMDc3R7t27XD48OFS6yYlJWHYsGHw8fGBXC5HWFiYTp1Vq1YhKCgI9vb2sLe3R48ePXDs2LFytY2IiIhqJ4MDUFRUFDZv3qxTvnnzZnz//fcG7Ss6OhphYWGYOXMmTp06haCgIPTu3RuJiYl66+fl5cHJyQkzZ85Eq1at9NY5ePAghg4digMHDiA2NhYNGjRAcHAwbty4YVDbiIiIqPYy+DF4Hx8ffPPNN+jWrZtW+aFDhzBu3DjEx8eXeV+BgYFo27YtVqxYoSnz9fVF//79sWjRosdu27VrV7Ru3RrLli17bD2VSgV7e3t8/fXXGDlyZJnaxcfgiYiIap5KfQz+6tWraNiwoU65p6dnqT03+uTn5+PEiRMIDg7WKg8ODsbRo0cNbVapcnNzUVBQgLp165ZaJy8vD5mZmVovIiIiqr0MDkDOzs74+++/dcpPnz4NBweHMu8nLS0NKpUKLi4uWuUuLi5ITk42tFmlmjZtGurVq4cePXqUWmfRokWws7PTvDw8PCrs+ERERFT9GByAhgwZgnfeeQcHDhyASqWCSqXC/v37MXnyZAwZMsTgBjy6rpgQ4rFrjRnis88+w4YNG7B161aYm5uXWm/69OnIyMjQvK5du1YhxyciIqLqyeDH4D/66CNcvXoV3bt3h4lJ0eZqtRojR47EwoULy7wfR0dHKBQKnd6eW7du6fQKlccXX3yBhQsX4tdff0XLli0fW1epVEKpVD71MYmIiKhmMLgHyMzMDNHR0YiPj8e6deuwdetWXLp0CZGRkTAzMzNoP+3atUNMTIxWeUxMDDp37mxos7R8/vnnWLBgAfbs2YOAgICn2hcRERHVPgb3ABVr0qQJmjRp8lQHnzJlCkJCQhAQEIBOnTph5cqVSExMxPjx4wEU3Zq6ceMG1qxZo9kmLi4OAJCdnY3U1FTExcXBzMwMfn5+AIpue82ePRvr16+Hl5eXpofJ2toa1tbWT9VeIiIiqh0Mfgx+4MCBCAgIwLRp07TKP//8cxw7dkzvHEGPEx4ejs8++wxJSUnw9/fH0qVL8dxzzwEomnQxISEBBw8efNhgPeODPD09kZCQAADw8vLC1atXderMmTMHc+fOLVOb+Bg8ERFRzWPI9dvgAOTk5IT9+/ejRYsWWuVnzpxBjx49kJKSYniLqxkGICIiopqnUucBys7O1jvWx9TUlPPnEBERUY1gcADy9/dHdHS0TvnGjRs143CIiIiIqjODB0HPnj0br776Ki5duoTnn38eALBv3z6sX78eP/74Y4U3kIiIiKiiGRyA+vXrh+3bt2PhwoX48ccfYWFhgVatWmH//v0cL0NEREQ1gsGDoB919+5drFu3DhERETh9+jRUKlVFtc1oOAiaiIio5qnUQdDF9u/fjxEjRsDd3R1ff/01+vTpg7/++qu8uyMiIiKqMgbdArt+/TpWr16NyMhI5OTkYNCgQSgoKMCWLVs4AJqIiIhqjDL3APXp0wd+fn44e/YsvvrqK9y8eRNfffVVZbaNiIiIqFKUuQdo7969eOeddzBhwoSnXgKDiIiIyJjK3AN0+PBhZGVlISAgAIGBgfj666+RmppamW0jIiIiqhRlDkCdOnXCqlWrkJSUhDfffBMbN25EvXr1oFarERMTg6ysrMpsJxEREVGFearH4OPj4xEREYEffvgBd+/eRc+ePbFjx46KbJ9R8DF4IiKimqdKHoMHAB8fH3z22We4fv06NmzY8DS7IiIiIqoyTz0RYm3EHiAiIqKap8p6gIiIiIhqIgYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcoweg8PBwNGzYEObm5mjXrh0OHz5cat2kpCQMGzYMPj4+kMvlCAsL01tvy5Yt8PPzg1KphJ+fH7Zt21ZJrSciIqKayKgBKDo6GmFhYZg5cyZOnTqFoKAg9O7dG4mJiXrr5+XlwcnJCTNnzkSrVq301omNjcXgwYMREhKC06dPIyQkBIMGDcKff/5ZmR+FiIiIahCZEEIY6+CBgYFo27YtVqxYoSnz9fVF//79sWjRosdu27VrV7Ru3RrLli3TKh88eDAyMzOxe/duTVmvXr1gb2+PDRs2lKldmZmZsLOzQ0ZGBmxtbcv+gYiIiMhoDLl+G60HKD8/HydOnEBwcLBWeXBwMI4ePVru/cbGxurs84UXXniqfRIREVHtYmKsA6elpUGlUsHFxUWr3MXFBcnJyeXeb3JyssH7zMvLQ15enubrzMzMch+fiIiIqj+jD4KWyWRaXwshdMoqe5+LFi2CnZ2d5uXh4fFUxyciIqLqzWgByNHREQqFQqdn5tatWzo9OIZwdXU1eJ/Tp09HRkaG5nXt2rVyH5+IiIiqP6MFIDMzM7Rr1w4xMTFa5TExMejcuXO599upUyedfe7du/ex+1QqlbC1tdV6ERERUe1ltDFAADBlyhSEhIQgICAAnTp1wsqVK5GYmIjx48cDKOqZuXHjBtasWaPZJi4uDgCQnZ2N1NRUxMXFwczMDH5+fgCAyZMn47nnnsOnn36Kl19+GT/99BN+/fVX/P7771X++YiIiKh6MmoAGjx4MNLT0zF//nwkJSXB398fu3btgqenJ4CiiQ8fnROoTZs2mr+fOHEC69evh6enJxISEgAAnTt3xsaNGzFr1izMnj0bjRo1QnR0NAIDA6vscxEREVH1ZtR5gKorzgNERERU89SIeYCIiIiIjIUBiIiIiCSHAYiIiIgkhwGIiIiIJIcBiIiIiCSHAYiIiIgkhwGIiIiIJIcBiIiIiCSHAYiIiIgkhwGIiIiIJMeoa4ERERGRtOTmF+J8SjaEEGjTwN5o7WAAIiIiogpXoFLjcmoO4lOycD45C/9LzsL5lCwk3s4FADzT2AHrxnY0WvsYgIiIiKjc1GqB63fuFQWdlAdBJzkLl9OyUaDSv966o7US9pZmVdxSbQxARERE9ERCCKRm5+F8cjbiU7IQn5yJ+JRsXEjJQm6+Su821koTNHWxho+rDXxcbND0wZ8O1soqbr0uBiAiIiLSknW/AOdTshCfnP0g6GThfEo2bufk661vppCjkbM1fFys4eNqCx9XazR1sUG9OhaQyWRV3PqyYQAiIiKSqLxCFS7eytYKO+dTsnHj7j299WUywMvBqqhXx8VGE3Y8HaxgqqhZD5YzABEREdVyKrXA1fSch0EnJRPxyVlISM+FSq1/nI6rrfmDW1YPenVcbNDY2RoWZooqbn3lYAAiIiKqJYQQSM68j/jkEgOSU7JwISUbeYVqvdvYmpugmastmro+DDpNXaxRx8iDlCsbAxAREVENdDc3XxN0igYlF70y7xfqra80kaOpiw2autigmevDAckutspqO06nMjEAERERVWP38lW4cCtLp1cnJTNPb32FXIaGjlYPxugUBR4fVxs0qGsJhVx6Qac0DEBERETVQIFKjYQ03YkDr97OhdA/TAf16lhoQk6zB382craC0qR2jNOpTAxAREREVUiIookDH711dTk1B/kq/eN06lqZaXp0igNPUxdr2JibVnHraw8GICIiokqSnp1XFHBKzJJ8ISUb2Xn6x+lYmimKblk9EnacbIw/cWBtwwBERET0lLLzCnH+wa2r4l6d8ylZSMvWP3GgqUKGRk7WmvE5xYGnXh0LyDlOp0owABEREZVRfqEal1KLJw7M0vTuXL9T+sSBDepaao3R8XG1QUPHmjdxYG3DAERERPQItVrg2p1czcKe/3vQu3MlLQeFpUwc6Gyj1HrqysfFBk1crGFpxkttdcR/FSIikiwhBFKz8jRPXBX36FxIyca9Av0LfNqYm2gW9tT06rjYwN6qdk8cWNswABERkSRk3CvQhJyS8+nczS3QW9/MRI4mztYP59N50KvjZmcuyYkDaxsGICIiqlXuFxQt8Plo0EnKuK+3vlwGeJWYOLC4d8ezriVMOE6n1mIAIiKiGqlQpcbV27mawcjFvTsJ6TkoZZgO3O3MNT05xeN1Gjtbw9yUEwdKDQMQERFVa0IIJGXcfzifzoNZki+mZiO/lAU+61iaas2lUzQg2QZ2Fpw4kIowABERUbVxJyf/4YDk4vE6yVnIKmXiQAtTBZq6lJhP50HYcbKR5gKfVHYMQEREVOVy8wtxPiVba+LA+JQspGbpX+DTRC6Dt5OVznw6HvaWnDiQyoUBiIiIKk2BSo0raTkP59N50LuTeDu31G086loUDUQu0avj7WgNMxMOSKaKwwBERERPTa0WuHH3nvZ8OslZuJyWjQKV/hHJjtZK+Lhaa/XqNHGxgbWSlyaqfPwuIyKiMhNCIC07X3tAckoWLqRkITdf/8SB1koTNHWx1nrE3MfFBg7WXOCTjIcBiIiI9Mq6XzxxYPaD+XQycT4lG7dz9C/waaaQo5GzNXxcrOHjaqvp3alXx4IDkqnaYQAiIpK4vEIVLt3KQXxKJuKTsxH/IOjcuFv6Ap9eDlYPenVsHzxubg0vBytOHEg1BgMQEZFEqNQCibdzEZ+cqdWrk5CeC1UpMwe62hZPHPgw7DR2toaFGScOpJqNAYiIqJYRQiAlM+/BLauiW1jxKZm4kJKNvFImDrQ1N0EzV1s0dX0YdJq6WKOOJRf4pNqJAYiIqAa7m5v/cBmIEk9fZd7XP3Gg0kSOpg8eMW9WYoFPF1tOHEjSwgBERFQD3MsvWuCzuFen+HHzlEz9Ewcq5DI0LLHAZ/GcOg3qWkLBiQOJGICIiKqTQpUaCekPJw4s7tW5ejsXopQFPuvVsdBaBqKpiw0aOVtBacJxOkSlYQAiIjICIYomDnx0gc/LqTnIV+kfp1PXykxrgc+mD8bp2JhzgU8iQzEAERFVsvTsvIdB58Htqwsp2cguZYFPSzNF0S2rR8KOkw0nDiSqKAxAREQVJDuvEOdTtG9dnU/JQlq2/okDTRUyNHIqsZL5gz/r1bHgAp9ElYwBiIjIQPmFalxOy9Y8cVXcu3P9TukTBzaoa6mzknlDRyuYcuJAIqNgACIiKoVaLXDtTq7OgOQraTkoLGXiQGcbpdZTVz4uNmjiYg1LM/53S1SdGP0nMjw8HJ9//jmSkpLQvHlzLFu2DEFBQaXWP3ToEKZMmYJ///0X7u7ueP/99zF+/HitOsuWLcOKFSuQmJgIR0dHDBw4EIsWLYK5uXllfxwiqoGEEEjNytNeyTylaJzOvQL9C3zamJtoFvbU9Oq42MDeihMHEtUERg1A0dHRCAsLQ3h4OJ555hl8++236N27N86ePYsGDRro1L9y5Qr69OmDN954A2vXrsWRI0fw1ltvwcnJCa+++ioAYN26dZg2bRoiIyPRuXNnnD9/HqNGjQIALF26tCo/HhFVQxn3CjQhp+R8OndzC/TWNzORo4mz9cP5dB706rjZmXPiQKIaTCZEaTNLVL7AwEC0bdsWK1as0JT5+vqif//+WLRokU79Dz74ADt27MC5c+c0ZePHj8fp06cRGxsLAJg4cSLOnTuHffv2aepMnToVx44dw+HDh8vUrszMTNjZ2SEjIwO2trbl/XhEZET3C4omDnw06CRl3NdbXy4DvEpMHFjcu+NZ15ILfBLVEIZcv43WA5Sfn48TJ05g2rRpWuXBwcE4evSo3m1iY2MRHBysVfbCCy8gIiICBQUFMDU1xbPPPou1a9fi2LFj6NChAy5fvoxdu3YhNDS01Lbk5eUhL+/hbKqZmZlP8cmIqCoVqtS4ejtXMxi5uHcnIT0HpQzTgbuduaYnp3i8TmNna5ibcuJAIqkwWgBKS0uDSqWCi4uLVrmLiwuSk5P1bpOcnKy3fmFhIdLS0uDm5oYhQ4YgNTUVzz77LIQQKCwsxIQJE3SCVkmLFi3CvHnznv5DEVGlEUIgKeO+zsSBF1OzkV/KAp91LE215tIpGpBsAzsLThxIJHVGHwT96D10IcRj76vrq1+y/ODBg/j4448RHh6OwMBAXLx4EZMnT4abmxtmz56td5/Tp0/HlClTNF9nZmbCw8OjXJ+HiJ7enZz8hwOSi8frJGchq5SJAy1MFWjqUmI+nQdhx8lGmgt8qtVq5Ofrn3uIqKYzMzODXP70t6WNFoAcHR2hUCh0entu3bql08tTzNXVVW99ExMTODg4AABmz56NkJAQjB07FgDQokUL5OTkYNy4cZg5c6bek6ZUKqFUcoZVoqqWm1+ICynZml6d4j9Ts/Qv8Gkil8HbyUpnPh0Pe0tOHPhAfn4+rly5ArVaf68YUU0nl8vRsGFDmJk93ROXRgtAZmZmaNeuHWJiYvDKK69oymNiYvDyyy/r3aZTp07473//q1W2d+9eBAQEwNS0qEs7NzdXJ+QoFAoIIWDE8d5EklagUuNKmu4Cn9fulL7Ap0ddC52VzL0drWFmwgHJpRFCICkpCQqFAh4eHhXyWzJRdaJWq3Hz5k0kJSWhQYMGT9XDa9RbYFOmTEFISAgCAgLQqVMnrFy5EomJiZp5faZPn44bN25gzZo1AIqe+Pr6668xZcoUvPHGG4iNjUVERAQ2bNig2Wffvn2xZMkStGnTRnMLbPbs2ejXrx8UCg5wJKpManXRAp9a8+kkZ+FyWjYKVPqTjqO1Ej6u1lq9Ok1dbGClNPod+hqnsLAQubm5cHd3h6WlpbGbQ1QpnJyccPPmTRQWFmo6P8rDqP/DDB48GOnp6Zg/fz6SkpLg7++PXbt2wdPTEwCQlJSExMRETf2GDRti165dePfdd7F8+XK4u7vjyy+/1MwBBACzZs2CTCbDrFmzcOPGDTg5OaFv3774+OOPq/zzEdVWQgikZedrD0hOycKFlCzk5uufONBaaYKmLtZaj5j7uNjAwZq3nyuKSlV07p/21gBRdVb8/a1SqZ4qABl1HqDqivMAET2Udb8A51NKzqeTifMp2bido3+QrZlCjkbO1vBxsYaPq62md6deHQtJDkiuSvfv38eVK1fQsGFDznxPtdbjvs9rxDxARFS95BWqcOlWDuJTMhGfnK25hXXjbukLfHo5WD3o1bF9MF7HGl4OVpw4kIyua9euaN26NZYtW2bsplA1xQBEJDEqtUDi7VzEJz8MOv9LzkRCei5Upcwc6GprrrPmVWNna1iYcVwdPZ0n9QqGhoZi9erVBu9369atT3V7pKSjR48iKCgIPXv2xJ49eypkn2R8DEBEtZQQAimZeQ9uWWUhPjkb8SmZuJCSjbxSJg60NTdBM1dbrTWvfFxsYGfJiQOpciQlJWn+Hh0djQ8//BDx8fGaMgsLC636xbP+P0ndunUrrI2RkZGYNGkSvvvuOyQmJupdq7KqlPXz05Oxn5qoFsjILcCxK7fxQ2wCZm0/g0HfxKL1/Bh0XLQPo6KOY+Gu/2HLyev450Ym8grVUJrI0aKeHV5tWx8z+/ji+9Ed8Mf07jg9JxibxnfCgv7+COnoiQ4N6zL8UKVydXXVvOzs7CCTyTRf379/H3Xq1MGmTZvQtWtXmJubY+3atUhPT8fQoUNRv359WFpaokWLFlpPAwNFt8DCwsI0X3t5eWHhwoUYPXo0bGxs0KBBA6xcufKJ7cvJycGmTZswYcIEvPTSS3p7o3bs2IGAgACYm5vD0dERAwYM0LyXl5eH999/Hx4eHlAqlWjSpAkiIiIAAKtXr0adOnW09rV9+3atXrG5c+eidevWiIyMhLe3N5RKJYQQ2LNnD5599lnUqVMHDg4OeOmll3Dp0iWtfV2/fh1DhgxB3bp1YWVlhYCAAPz5559ISEiAXC7HX3/9pVX/q6++gqenp2SmjGEPEFENci+/aIFPTa9OSjbikzORkql/4kCFXIaGJRb4LJ5Pp0FdSyg4cWCtJ4TAvQL9T+VVNgtTRYUNev/ggw+wePFiREVFQalU4v79+2jXrh0++OAD2NraYufOnQgJCYG3tzcCAwNL3c/ixYuxYMECzJgxAz/++CMmTJiA5557Ds2aNSt1m+joaPj4+MDHxwcjRozApEmTMHv2bM1n27lzJwYMGICZM2fihx9+QH5+Pnbu3KnZfuTIkYiNjcWXX36JVq1a4cqVK0hLSzPo81+8eBGbNm3Cli1bNNO55OTkYMqUKZrJfj/88EO88soriIuLg1wuR3Z2Nrp06YJ69ephx44dcHV1xcmTJ6FWq+Hl5YUePXogKioKAQEBmuNERUVh1KhRknlYgQGIqBoqVKmRkK47ceDV26VPHFivjoXWMhBNXWzQyNkKShOO05GqewUq+H34i1GOfXb+C7A0q5hLTFhYmFavCgC89957mr9PmjQJe/bswebNmx8bgPr06YO33noLQFGoWrp0KQ4ePPjYABQREYERI0YAAHr16oXs7Gzs27cPPXr0AAB8/PHHGDJkiNZ6kq1atQIAnD9/Hps2bUJMTIymvre3tyEfHUDR7N4//PADnJycNGUlp38pbqezszPOnj0Lf39/rF+/HqmpqTh+/LjmdmDjxo019ceOHYvx48djyZIlUCqVOH36NOLi4rB161aD21dTMQARGZEQRRMHFg1EfrjA5+XUHOSr9I/TqWtlprXAZ9HEgdawMeetKqqdSvZSAEXzv3zyySeIjo7GjRs3kJeXh7y8PFhZWT12Py1bttT8vfhW261bt0qtHx8fj2PHjmlCgYmJCQYPHozIyEhNoImLi8Mbb7yhd/u4uDgoFAp06dKlTJ+zNJ6enlrhBwAuXbqE2bNn448//kBaWppm6ZPExET4+/sjLi4Obdq0KXUsVP/+/TFx4kRs27YNQ4YMQWRkJLp16wYvL6+namtNwgBEVEXSs/MeLuyp+TMb2aUs8GlpptA8cVUy7DjZcOJAKhsLUwXOzn/BaMeuKI8Gm8WLF2Pp0qVYtmwZWrRoASsrK4SFhT1xAdhHBw/LZLLHrpkWERGBwsJC1KtXT1MmhICpqSnu3LkDe3t7nUHaJT3uPaBoTatHx9sUFBTo1NMX7Pr27QsPDw+sWrUK7u7uUKvV8Pf315yDJx3bzMwMISEhiIqKwoABA7B+/XrJTRnAAERUwbLzCnGhxMKexWEnLVv/f86mChkaOZVYyfzBn/XqWHCBT3oqMpmswm5DVSeHDx/Gyy+/rLk1pVarceHCBfj6+lbYMQoLC7FmzRosXrwYwcHBWu+9+uqrWLduHSZOnIiWLVti3759eP3113X20aJFC6jVahw6dEjTY1SSk5MTsrKykJOTowk5cXFxT2xbeno6zp07h2+//RZBQUEAgN9//12rTsuWLfHdd9/h9u3bpfYCjR07Fv7+/ggPD0dBQYHObcbarvb9ZBBVkfxCNS6nZWvWuyq+jXX9TukTBzaoa6mzknlDRyuYcuJAojJr3LgxtmzZgqNHj8Le3h5LlixBcnJyhQagn3/+GXfu3MGYMWNgZ2en9d7AgQMRERGBiRMnYs6cOejevTsaNWqEIUOGoLCwELt378b7778PLy8vhIaGYvTo0ZpB0FevXsWtW7cwaNAgBAYGwtLSEjNmzMCkSZNw7NixMs15ZG9vDwcHB6xcuRJubm5ITEzEtGnTtOoMHToUCxcuRP/+/bFo0SK4ubnh1KlTcHd3R6dOnQAAvr6+6NixIz744AOMHj36ib1GtQ0DENETqNUC1+7kaoJO8W2sK2k5KCxl4kBnG6XWU1c+LjZo4mJdK38bJ6pqs2fPxpUrV/DCCy/A0tIS48aNQ//+/ZGRkVFhx4iIiECPHj10wg9Q1AO0cOFCnDx5El27dsXmzZuxYMECfPLJJ7C1tcVzzz2nqbtixQrMmDEDb731FtLT09GgQQPMmDEDQNFcRWvXrsX//d//YeXKlejRowfmzp2LcePGPbZtcrkcGzduxDvvvAN/f3/4+Pjgyy+/RNeuXTV1zMzMsHfvXkydOhV9+vRBYWEh/Pz8sHz5cq19jRkzBkePHsXo0aOf4mzVTFwLTA+uBSZNQgikZj0cp1Pcq3M+JbvUR4ltzE00C3uWnCXZ3oqLUVLV41pgZKiPP/4YGzduxJkzZ4zdlDLjWmBETyHjXgEuFD95VWK8zt1c3QGIAGBmIkcTZ+uH8+k86NVxszOXzJwZRFR7ZGdn49y5c/jqq6+wYMECYzfHKBiAqFa7X1A0caDmyasHYScp477e+nIZ4FVi4sDi3h3PupZc4JOIao2JEydiw4YN6N+/vyRvfwEMQFRLFKrUuHo7VzOPTnHYSUjLQSnDdOBuV7TAZ8mJAxs7W8O8Ah/fJSKqjlavXl2uRWZrEwYgqlGEEEjKuP9wPp0Ht64u3MpGfikLfNaxNNWaS6e4V8eWEwcSEUkWAxBVW3dy8h8OSE55GHay7uufONDCVIGmLiXm03kQdpxslBynQ0REWhiAyOhy8wtxISVba+LA/yVnITVL/wKfJnIZvJ2sdObT8bC35MSBRERUJgxAVGUKVGpcSdNd4PPandIX+PSoa6Gzkrm3ozXMTDggmYiIyo8BiCqcWl20wGfJSQPPp2ThUmo2ClT6k46jtRI+rtbwcbGFj6v1gwU+bWCl5LcoERFVPF5dqNyEEEjLztdayTw+JQsXUrKQk69/4kBrpQmauljDx9UWPi7Wmvl0HKy5wCcREVUdBiAqk6z7BTifkq21knl8ShZu5+hf4NNMIUcjZ2v4FIedB7069epYcEAyEVW4rl27onXr1poVzb28vBAWFoawsLBSt5HJZNi2bRv69+//VMeuqP1Q1WIAIi15hSpcupWD+JRMxCdna8LOjbulL/Dp5WBVolfHBj6u1vBysOLEgUT0RH379sW9e/fw66+/6rwXGxuLzp0748SJE2jbtq1B+z1+/LhmhfWKMnfuXGzfvl1nxfakpCTY29tX6LFKc+/ePbi7u0Mmk+HGjRuSW8C0IjEASZRKLZB4O1drzav4lKIFPlWlzBzoamuus+ZVY2drWJhx4kAiKp8xY8ZgwIABuHr1Kjw9PbXei4yMROvWrQ0OPwDg5ORUUU18IldX1yo71pYtW+Dv7w8hBLZu3Yrhw4dX2bEfJYSASqWCiUnNjBL8Fb2WE0IgOeM+Dp1PxcrfLmHqptPo+9XvaD5nD7p9cRDj157A0l/PY+eZJFy8lQ2VWsDW3AQdvOoipKMnFvT3x6Y3O+H0h8H4Y0Z3rBndATP6+GJgu/poUd+O4YeInspLL70EZ2dnnVmJc3NzER0djTFjxiA9PR1Dhw5F/fr1YWlpiRYtWmDDhg2P3a+Xl5fmdhgAXLhwAc899xzMzc3h5+eHmJgYnW0++OADNG3aFJaWlvD29sbs2bNRUFC0PuDq1asxb948nD59GjKZDDKZTNNmmUyG7du3a/Zz5swZPP/887CwsICDgwPGjRuH7OxszfujRo1C//798cUXX8DNzQ0ODg54++23Ncd6nIiICIwYMQIjRoxARESEzvv//vsvXnzxRdja2sLGxgZBQUG4dOmS5v3IyEg0b94cSqUSbm5umDhxIgAgISEBMplMq3fr7t27kMlkOHjwIADg4MGDkMlk+OWXXxAQEAClUonDhw/j0qVLePnll+Hi4gJra2u0b99ep0cvLy8P77//Pjw8PKBUKtGkSRNERERACIHGjRvjiy++0Kr/zz//QC6Xa7W9otXM2EZ6ZeQWPHjqKvPBxIHZiE/JQsY9/T9U5qZyNHG2eTifzoMByS62nDiQqFYQAijINc6xTS2L7pE/gYmJCUaOHInVq1fjww8/1Pzfs3nzZuTn52P48OHIzc1Fu3bt8MEHH8DW1hY7d+5ESEgIvL29ERgY+MRjqNVqDBgwAI6Ojvjjjz+QmZmpd2yQjY0NVq9eDXd3d5w5cwZvvPEGbGxs8P7772Pw4MH4559/sGfPHs3F3c7OTmcfubm56NWrFzp27Ijjx4/j1q1bGDt2LCZOnKgV8g4cOAA3NzccOHAAFy9exODBg9G6dWu88cYbpX6OS5cuITY2Flu3boUQAmFhYbh8+TK8vb0BADdu3MBzzz2Hrl27Yv/+/bC1tcWRI0dQWFg0eeyKFSswZcoUfPLJJ+jduzcyMjJw5MiRJ56/R73//vv44osv4O3tjTp16uD69evo06cPPvroI5ibm+P7779H3759ER8fjwYNGgAARo4cidjYWHz55Zdo1aoVrly5grS0NMhkMowePRpRUVF47733NMeIjIxEUFAQGjVqZHD7yooBqAa6l1+0wOf/kjMf3LrKRnxyJlIy9U8cqJDL0LDEAp/F8+k0qGsJBScOJKq9CnKBhe7GOfaMm4BZ2cbgjB49Gp9//jkOHjyIbt26ASi6AA4YMAD29vawt7fXujhOmjQJe/bswebNm8sUgH799VecO3cOCQkJqF+/PgBg4cKF6N27t1a9WbNmaf7u5eWFqVOnIjo6Gu+//z4sLCxgbW0NExOTx97yWrduHe7du4c1a9ZoxiB9/fXX6Nu3Lz799FO4uLgAAOzt7fH1119DoVCgWbNmePHFF7Fv377HBqDIyEj07t1bM96oV69eiIyMxEcffQQAWL58Oezs7LBx40aYmhYt9dO0aVPN9h999BGmTp2KyZMna8rat2//xPP3qPnz56Nnz56arx0cHNCqVSut42zbtg07duzAxIkTcf78eWzatAkxMTHo0aMHAGhCGwC8/vrr+PDDD3Hs2DF06NABBQUFWLt2LT7//HOD22YIBqBqrFClRkJ6DuKTszW9OvHJWbh6u/SJA+vVsdBe88rFBo2craA04a0qIqqemjVrhs6dOyMyMhLdunXDpUuXcPjwYezduxcAoFKp8MknnyA6Oho3btxAXl4e8vLyyjzI+dy5c2jQoIEm/ABAp06ddOr9+OOPWLZsGS5evIjs7GwUFhbC1tbWoM9y7tw5tGrVSqttzzzzDNRqNeLj4zUBqHnz5lAoHv6/7ObmhjNnzpS6X5VKhe+//x7/+c9/NGUjRozAu+++i3nz5kGhUCAuLg5BQUGa8FPSrVu3cPPmTXTv3t2gz6NPQECA1tc5OTmYN28efv75Z9y8eROFhYW4d+8eEhMTAQBxcXFQKBTo0qWL3v25ubnhxRdfRGRkJDp06ICff/4Z9+/fx2uvvfbUbX0cBqBqQIiiiQO159PJxqVb2chX6V/gs66VmdYCn0UTB1rDhgt8ElExU8uinhhjHdsAY8aMwcSJE7F8+XJERUXB09NTc7FevHgxli5dimXLlqFFixawsrJCWFgY8vP1T8PxKKHnN8ZHb/P/8ccfGDJkCObNm4cXXnhB05OyePFigz6HEKLUIQQlyx8NKTKZDGq1/v/vAeCXX37BjRs3MHjwYK1ylUqFvXv3onfv3o99IuxJT4vJ5XJN+4uVNibp0eD5f//3f/jll1/wxRdfoHHjxrCwsMDAgQM1/z5leVJt7NixCAkJwdKlSxEVFYXBgwfD0tKw7yFDMQBVsfTsPK3ZkYv+zEZ2nv4FPi3NFJonrkqGHScbThxIRE8gk5X5NpSxDRo0CJMnT8b69evx/fff44033tAEhsOHD+Pll1/GiBEjABSN6blw4QJ8fX3LtG8/Pz8kJibi5s2bcHcvuiUYGxurVefIkSPw9PTEzJkzNWVXr17VqmNmZgaVSv8kryWP9f333yMnJ0cTFI4cOQK5XK51O8pQERERGDJkiFb7AOCTTz5BREQEevfujZYtW+L7779HQUGBTsCysbGBl5cX9u3bp7nNWFLxU3NJSUlo06YNAOg87l+aw4cPY9SoUXjllVcAANnZ2UhISNC836JFC6jVahw6dEhzC+xRffr0gZWVFVasWIHdu3fjt99+K9OxnwYDUBXady4FY77/S+97pgoZGjmVWMn8wZ/16lhwgU8iqvWsra0xePBgzJgxAxkZGRg1apTmvcaNG2PLli04evQo7O3tsWTJEiQnJ5c5APXo0QM+Pj4YOXIkFi9ejMzMTJ0g0bhxYyQmJmLjxo1o3749du7ciW3btmnV8fLywpUrVxAXF4f69evDxsYGSqX2L6PDhw/HnDlzEBoairlz5yI1NRWTJk1CSEiI5vaXoVJTU/Hf//4XO3bsgL+/v9Z7oaGhePHFF5GamoqJEyfiq6++wpAhQzB9+nTY2dnhjz/+QIcOHeDj44O5c+di/PjxcHZ2Ru/evZGVlYUjR45g0qRJsLCwQMeOHfHJJ5/Ay8sLaWlpWmOiHqdx48bYunUr+vbtC5lMhtmzZ2v1Znl5eSE0NBSjR4/WDIK+evUqbt26hUGDBgEAFAoFRo0ahenTp6Nx48Z6b1FWND4GX4UaO1tDJgM8HSzR088Fk55vjK+GtsHed5/D2fm9sCfsOXw5tA3e7tYYPfxc4FGXq5sTkXSMGTMGd+7cQY8ePTRPDwHA7Nmz0bZtW7zwwgvo2rUrXF1dDZp1WS6XY9u2bcjLy0OHDh0wduxYfPzxx1p1Xn75Zbz77ruYOHEiWrdujaNHj2L27NladV599VX06tUL3bp1g5OTk95H8S0tLfHLL7/g9u3baN++PQYOHIju3bvj66+/NuxklFA8oFrf+J1u3brBxsYGP/zwAxwcHLB//35kZ2ejS5cuaNeuHVatWqXpDQoNDcWyZcsQHh6O5s2b46WXXsKFCxc0+4qMjERBQQECAgIwefJkzeDqJ1m6dCns7e3RuXNn9O3bFy+88ILO3E0rVqzAwIED8dZbb6FZs2Z44403kJOTo1VnzJgxyM/Px+jRow09ReUiE/pujkpcZmYm7OzskJGRYfAAuMdRqwXuF6pgacaONyKqePfv38eVK1fQsGFDmJubG7s5RAY5cuQIunbtiuvXrz+2t+xx3+eGXL95Ja5CcrmM4YeIiKiEvLw8XLt2DbNnz8agQYPKfavQULwFRkREREazYcMG+Pj4ICMjA5999lmVHZcBiIiIiIxm1KhRUKlUOHHiBOrVq1dlx2UAIiIiIslhACIiIiLJYQAiIqpl+HAv1WYV9f3NAEREVEsUry1V1iUiiGqi4u/vkmuplQefySYiqiVMTExgaWmJ1NRUmJqaatZ3Iqot1Go1UlNTYWlpCROTp4swDEBERLWETCaDm5sbrly5orOOFVFtIZfL0aBBg1IXnS0rBiAiolrEzMwMTZo04W0wqrXMzMwqpHeTAYiIqJaRy+VcCoPoCXiDmIiIiCSHAYiIiIgkhwGIiIiIJIdjgPQonmQpMzPTyC0hIiKisiq+bpdlskQGID2ysrIAAB4eHkZuCRERERkqKysLdnZ2j60jE5wzXYdarcbNmzdhY2Pz1PMMPCozMxMeHh64du0abG1tK3Tf9BDPc9Xgea4aPM9Vh+e6alTWeRZCICsrC+7u7k98VJ49QHrI5XLUr1+/Uo9ha2vLH64qwPNcNXieqwbPc9Xhua4alXGen9TzU4yDoImIiEhyGICIiIhIchiAqphSqcScOXOgVCqN3ZRajee5avA8Vw2e56rDc101qsN55iBoIiIikhz2ABEREZHkMAARERGR5DAAERERkeQwABEREZHkMABVgvDwcDRs2BDm5uZo164dDh8+/Nj6hw4dQrt27WBubg5vb2988803VdTSms2Q87x161b07NkTTk5OsLW1RadOnfDLL79UYWtrLkO/n4sdOXIEJiYmaN26deU2sJYw9Dzn5eVh5syZ8PT0hFKpRKNGjRAZGVlFra25DD3P69atQ6tWrWBpaQk3Nze8/vrrSE9Pr6LW1ky//fYb+vbtC3d3d8hkMmzfvv2J2xjlOiioQm3cuFGYmpqKVatWibNnz4rJkycLKysrcfXqVb31L1++LCwtLcXkyZPF2bNnxapVq4Spqan48ccfq7jlNYuh53ny5Mni008/FceOHRPnz58X06dPF6ampuLkyZNV3PKaxdDzXOzu3bvC29tbBAcHi1atWlVNY2uw8pznfv36icDAQBETEyOuXLki/vzzT3HkyJEqbHXNY+h5Pnz4sJDL5eI///mPuHz5sjh8+LBo3ry56N+/fxW3vGbZtWuXmDlzptiyZYsAILZt2/bY+sa6DjIAVbAOHTqI8ePHa5U1a9ZMTJs2TW/9999/XzRr1kyr7M033xQdO3astDbWBoaeZ338/PzEvHnzKrpptUp5z/PgwYPFrFmzxJw5cxiAysDQ87x7925hZ2cn0tPTq6J5tYah5/nzzz8X3t7eWmVffvmlqF+/fqW1sbYpSwAy1nWQt8AqUH5+Pk6cOIHg4GCt8uDgYBw9elTvNrGxsTr1X3jhBfz1118oKCiotLbWZOU5z49Sq9XIyspC3bp1K6OJtUJ5z3NUVBQuXbqEOXPmVHYTa4XynOcdO3YgICAAn332GerVq4emTZvivffew71796qiyTVSec5z586dcf36dezatQtCCKSkpODHH3/Eiy++WBVNlgxjXQe5GGoFSktLg0qlgouLi1a5i4sLkpOT9W6TnJyst35hYSHS0tLg5uZWae2tqcpznh+1ePFi5OTkYNCgQZXRxFqhPOf5woULmDZtGg4fPgwTE/73UhblOc+XL1/G77//DnNzc2zbtg1paWl46623cPv2bY4DKkV5znPnzp2xbt06DB48GPfv30dhYSH69euHr776qiqaLBnGug6yB6gSyGQyra+FEDplT6qvr5y0GXqei23YsAFz585FdHQ0nJ2dK6t5tUZZz7NKpcKwYcMwb948NG3atKqaV2sY8v2sVqshk8mwbt06dOjQAX369MGSJUuwevVq9gI9gSHn+ezZs3jnnXfw4Ycf4sSJE9izZw+uXLmC8ePHV0VTJcUY10H+ilaBHB0doVAodH6buHXrlk66Lebq6qq3vomJCRwcHCqtrTVZec5zsejoaIwZMwabN29Gjx49KrOZNZ6h5zkrKwt//fUXTp06hYkTJwIoulALIWBiYoK9e/fi+eefr5K21yTl+X52c3NDvXr1YGdnpynz9fWFEALXr19HkyZNKrXNNVF5zvOiRYvwzDPP4P/+7/8AAC1btoSVlRWCgoLw0UcfsYe+ghjrOsgeoApkZmaGdu3aISYmRqs8JiYGnTt31rtNp06ddOrv3bsXAQEBMDU1rbS21mTlOc9AUc/PqFGjsH79et7DLwNDz7OtrS3OnDmDuLg4zWv8+PHw8fFBXFwcAgMDq6rpNUp5vp+feeYZ3Lx5E9nZ2Zqy8+fPQy6Xo379+pXa3pqqPOc5NzcXcrn2ZVKhUAB42ENBT89o18FKHWItQcWPWUZERIizZ8+KsLAwYWVlJRISEoQQQkybNk2EhIRo6hc//vfuu++Ks2fPioiICD4GXwaGnuf169cLExMTsXz5cpGUlKR53b1711gfoUYw9Dw/ik+BlY2h5zkrK0vUr19fDBw4UPz777/i0KFDokmTJmLs2LHG+gg1gqHnOSoqSpiYmIjw8HBx6dIl8fvvv4uAgADRoUMHY32EGiErK0ucOnVKnDp1SgAQS5YsEadOndJMN1BdroMMQJVg+fLlwtPTU5iZmYm2bduKQ4cOad4LDQ0VXbp00ap/8OBB0aZNG2FmZia8vLzEihUrqrjFNZMh57lLly4CgM4rNDS06htewxj6/VwSA1DZGXqez507J3r06CEsLCxE/fr1xZQpU0Rubm4Vt7rmMfQ8f/nll8LPz09YWFgINzc3MXz4cHH9+vUqbnXNcuDAgcf+f1tdroMyIdiPR0RERNLCMUBEREQkOQxAREREJDkMQERERCQ5DEBEREQkOQxAREREJDkMQERERCQ5DEBEREQkOQxARESlkMlk2L59u7GbQUSVgAGIiKqlUaNGQSaT6bx69epl7KYRUS3A1eCJqNrq1asXoqKitMqUSqWRWkNEtQl7gIio2lIqlXB1ddV62dvbAyi6PbVixQr07t0bFhYWaNiwITZv3qy1/ZkzZ/D888/DwsICDg4OGDdunNYK6gAQGRmJ5s2bQ6lUws3NDRMnTtR6Py0tDa+88gosLS3RpEkT7NixQ/PenTt3MHz4cDg5OcHCwgJNmjTRCWxEVD0xABFRjTV79my8+uqrOH36NEaMGIGhQ4fi3LlzAIDc3Fz06tUL9vb2OH78ODZv3oxff/1VK+CsWLECb7/9NsaNG4czZ85gx44daNy4sdYx5s2bh0GDBuHvv/9Gnz59MHz4cNy+fVtz/LNnz2L37t04d+4cVqxYAUdHx6o7AURUfpW+3CoRUTmEhoYKhUIhrKystF7z588XQggBQIwfP15rm8DAQDFhwgQhhBArV64U9vb2Ijs7W/P+zp07hVwuF8nJyUIIIdzd3cXMmTNLbQMAMWvWLM3X2dnZQiaTid27dwshhOjbt694/fXXK+YDE1GV4hggIqq2unXrhhUrVmiV1a1bV/P3Tp06ab3XqVMnxMXFAQDOnTuHVq1awcrKSvP+M888A7Vajfj4eMhkMty8eRPdu3d/bBtatmyp+buVlRVsbGxw69YtAMCECRPw6quv4uTJkwgODkb//v3RuXPncn1WIqpaDEBEVG1ZWVnp3JJ6EplMBgAQQmj+rq+OhYVFmfZnamqqs61arQYA9O7dG1evXsXOnTvx66+/onv37nj77bfxxRdfGNRmIqp6HANERDXWH3/8ofN1s2bNAAB+fn6Ii4tDTk6O5v0jR45ALpejadOmsLGxgZeXF/bt2/dUbXBycsKoUaOwdu1aLFu2DCtXrnyq/RFR1WAPEBFVW3l5eUhOTtYqMzEx0Qw03rx5MwICAvDss89i3bp1OHbsGCIiIgAAw4cPx5w5cxAaGoq5c+ciNTUVkyZNQkhICFxcXAAAc+fOxfjx4+Hs7IzevXsjKysLR44cwaRJk8rUvg8//BDt2rVD8+bNkZeXh59//hm+vr4VeAaIqLIwABFRtbVnzx64ublplfn4+OB///sfgKIntDZu3Ii33noLrq6uWLduHfz8/AAAlpaW+OWXXzB58mS0b98elpaWePXVV7FkyRLNvkJDQ3H//n0sXboU7733HhwdHTFw4MAyt8/MzAzTp09HQkICLCwsEBQUhI0bN1bAJyeiyiYTQghjN4KIyFAymQzbtm1D//79jd0UIqqBOAaIiIiIJIcBiIiIiCSHY4CIqEbi3XsiehrsASIiIiLJYQAiIiIiyWEAIiIiIslhACIiIiLJYQAiIiIiyWEAIiIiIslhACIiIiLJYQAiIiIiyWEAIiIiIsn5f9xVHCkSgC34AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d89869e-b281-44d4-a602-5e7e463a920c",
   "metadata": {},
   "source": [
    "We can see that our model **validation accuracy** performance is **17%**, which is not good per-say, but considering that we have 2711 classes our model performs about 500 times better than random chance *(1/2711)*, which should serve as proof of concept and indicate that our model will perform significantly better, when trained in an environment with more effective hardware, allowing for increased training parameters and more iterations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
